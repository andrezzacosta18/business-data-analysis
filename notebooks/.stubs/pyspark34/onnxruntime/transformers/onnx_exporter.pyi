from _typeshed import Incomplete
from benchmark_helper import Precision
from onnxruntime.transformers.models.gpt2.gpt2_helper import GPT2ModelNoPastState as GPT2ModelNoPastState, PRETRAINED_GPT2_MODELS as PRETRAINED_GPT2_MODELS, TFGPT2ModelNoPastState as TFGPT2ModelNoPastState

logger: Incomplete
torch_func: Incomplete

def triu_onnx(x, diagonal: int = 0, out: Incomplete | None = None): ...
def replace_torch_functions() -> None: ...
def restore_torch_functions() -> None: ...
def create_onnxruntime_input(vocab_size, batch_size, sequence_length, input_names, config, data_type=...): ...
def filter_inputs(inputs, input_names): ...
def flatten(inputs): ...
def update_flatten_list(inputs, res_list): ...
def build_dynamic_axes(example_inputs, outputs_flatten): ...
def validate_onnx_model(onnx_model_path, example_inputs, example_outputs_flatten, use_gpu, fp16, output_names: Incomplete | None = None): ...
def get_onnx_file_path(onnx_dir: str, model_name: str, input_count: int, optimized_by_script: bool, use_gpu: bool, precision: Precision, optimized_by_onnxruntime: bool, use_external_data: bool): ...
def add_filename_suffix(file_path: str, suffix: str) -> str:
    """
    Append a suffix at the filename (before the extension).
    Args:
        path: pathlib.Path The actual path object we would like to add a suffix
        suffix: The suffix to add
    Returns: path with suffix appended at the end of the filename and before extension
    """
def optimize_onnx_model_by_ort(onnx_model_path, ort_model_path, use_gpu, overwrite, model_fusion_statistics) -> None: ...
def optimize_onnx_model(onnx_model_path, optimized_model_path, model_type, num_attention_heads, hidden_size, use_gpu, precision, use_raw_attention_mask, overwrite, model_fusion_statistics, use_external_data_format, optimization_options: Incomplete | None = None) -> None: ...
def modelclass_dispatcher(model_name, custom_model_class): ...
def load_pretrained_model(model_name, config, cache_dir, custom_model_class, is_tf_model: bool = False): ...
def load_pt_model(model_name, model_class, cache_dir, config_modifier): ...
def load_tf_model(model_name, model_class, cache_dir, config_modifier): ...
def load_pt_model_from_tf(model_name): ...
def validate_and_optimize_onnx(model_name, use_external_data_format, model_type, onnx_dir, input_names, use_gpu, precision, optimize_info, validate_onnx, use_raw_attention_mask, overwrite, config, model_fusion_statistics, onnx_model_path, example_inputs, example_outputs_flatten, output_names, fusion_options): ...
def export_onnx_model_from_pt(model_name, opset_version, use_external_data_format, model_type, model_class, config_modifier, cache_dir, onnx_dir, input_names, use_gpu, precision, optimizer_info, validate_onnx, use_raw_attention_mask, overwrite, model_fusion_statistics, fusion_options): ...
def export_onnx_model_from_tf(model_name, opset_version, use_external_data_format, model_type, model_class, config_modifier, cache_dir, onnx_dir, input_names, use_gpu, precision, optimizer_info, validate_onnx, use_raw_attention_mask, overwrite, model_fusion_statistics, fusion_options): ...
