from _typeshed import Incomplete
from nni import ClassArgsValidator as ClassArgsValidator
from nni.tuner import Tuner as Tuner
from nni.utils import OptimizeMode as OptimizeMode, extract_scalar_reward as extract_scalar_reward, json2parameter as json2parameter, json2space as json2space, split_index as split_index

logger: Incomplete

def perturbation(hyperparameter_type, value, resample_probablity, uv, ub, lv, lb, random_state):
    """
    Perturbation for hyperparameters

    Parameters
    ----------
    hyperparameter_type : str
        type of hyperparameter
    value : list
        parameters for sampling hyperparameter
    resample_probability : float
        probability for resampling
    uv : float/int
        upper value after perturbation
    ub : float/int
        upper bound
    lv : float/int
        lower value after perturbation
    lb : float/int
        lower bound
    random_state : RandomState
        random state
    """
def exploit_and_explore(bot_trial_info, top_trial_info, factor, resample_probability, epoch, search_space) -> None:
    """
    Replace checkpoint of bot_trial with top, and perturb hyperparameters

    Parameters
    ----------
    bot_trial_info : TrialInfo
        bottom model whose parameters should be replaced
    top_trial_info : TrialInfo
        better model
    factor : float
        factor for perturbation
    resample_probability : float
        probability for resampling
    epoch : int
        step of PBTTuner
    search_space : dict
        search_space to keep perturbed hyperparameters in range
    """

class TrialInfo:
    """
    Information of each trial, refresh for each epoch

    """
    checkpoint_dir: Incomplete
    hyper_parameters: Incomplete
    parameter_id: Incomplete
    score: Incomplete
    def __init__(self, checkpoint_dir: Incomplete | None = None, hyper_parameters: Incomplete | None = None, parameter_id: Incomplete | None = None, score: Incomplete | None = None) -> None: ...
    def clean_id(self) -> None: ...

class PBTClassArgsValidator(ClassArgsValidator):
    def validate_class_args(self, **kwargs) -> None: ...

class PBTTuner(Tuner):
    """
    Population Based Training (PBT) comes from `Population Based Training of Neural Networks <https://arxiv.org/abs/1711.09846v1>`__.
    It's a simple asynchronous optimization algorithm which effectively utilizes a fixed computational budget to jointly optimize
    a population of models and their hyperparameters to maximize performance.
    Importantly, PBT discovers a schedule of hyperparameter settings rather than following the generally sub-optimal strategy of
    trying to find a single fixed set to use for the whole course of training.

    .. image:: ../../img/pbt.jpg

    PBT tuner initializes a population with several trials (i.e., ``population_size``).
    There are four steps in the above figure, each trial only runs by one step. How long is one step is controlled by trial code,
    e.g., one epoch. When a trial starts, it loads a checkpoint specified by PBT tuner and continues to run one step,
    then saves checkpoint to a directory specified by PBT tuner and exits.
    The trials in a population run steps synchronously, that is, after all the trials finish the ``i``-th step,
    the ``(i+1)``-th step can be started. Exploitation and exploration of PBT are executed between two consecutive steps.

    Two important steps to follow if you are trying to use PBT tuner:

    1. **Provide checkpoint directory**. Since some trials need to load other trial's checkpoint,
       users should provide a directory (i.e., ``all_checkpoint_dir``) which is accessible by every trial.
       It is easy for local mode, users could directly use the default directory or specify any directory on the local machine.
       For other training services, users should follow
       :doc:`the document of those training services </experiment/training_service/shared_storage>`
       to provide a directory in a shared storage, such as NFS, Azure storage.

    2. **Modify your trial code**. Before running a step, a trial needs to load a checkpoint,
       the checkpoint directory is specified in hyper-parameter configuration generated by PBT tuner,
       i.e., ``params['load_checkpoint_dir']``. Similarly, the directory for saving checkpoint is also included in the configuration,
       i.e., ``params['save_checkpoint_dir']``. Here, ``all_checkpoint_dir`` is base folder of ``load_checkpoint_dir``
       and ``save_checkpoint_dir`` whose format is ``all_checkpoint_dir/<population-id>/<step>``.

       .. code-block:: python

        params = nni.get_next_parameter()
        # the path of the checkpoint to load
        load_path = os.path.join(params['load_checkpoint_dir'], 'model.pth')
        # load checkpoint from `load_path`
        ...
        # run one step
        ...
        # the path for saving a checkpoint
        save_path = os.path.join(params['save_checkpoint_dir'], 'model.pth')
        # save checkpoint to `save_path`
        ...

    The complete example code can be found :githublink:`here <examples/trials/mnist-pbt-tuner-pytorch>`.

    Parameters
    ----------
    optimize_mode : ``maximize`` or ``minimize``, default: ``maximize``
        If ``maximize``, the tuner will target to maximize metrics. If ``minimize``, the tuner will target to minimize metrics.
    all_checkpoint_dir : str
        Directory for trials to load and save checkpoint.
        If not specified, the directory would be ``~/nni/checkpoint/``.
        Note that if the experiment is not local mode,
        users should provide a path in a shared storage which can be accessed by all the trials.
    population_size : int, default = 10
        Number of trials in a population. Each step has this number of trials.
        In our implementation, one step is running each trial by specific training epochs set by users.
    factor : float, default = (1.2, 0.8)
        Factors for perturbation of hyperparameters.
    resample_probability : float, default = 0.25
        Probability for resampling.
    fraction : float, default = 0.2
        Fraction for selecting bottom and top trials.

    Examples
    --------
    Below is an example of PBT tuner configuration in experiment config file.

    .. code-block:: yaml

        tuner:
          name: PBT
          classArgs:
            optimize_mode: maximize
            all_checkpoint_dir: /the/path/to/store/checkpoints
            population_size: 10

    Notes
    -----
    Assessor is not allowed if PBT tuner is used.
    """
    optimize_mode: Incomplete
    all_checkpoint_dir: Incomplete
    population_size: Incomplete
    factor: Incomplete
    resample_probability: Incomplete
    fraction: Incomplete
    population: Incomplete
    pos: int
    param_ids: Incomplete
    running: Incomplete
    finished: Incomplete
    credit: int
    finished_trials: int
    epoch: int
    searchspace_json: Incomplete
    space: Incomplete
    send_trial_callback: Incomplete
    def __init__(self, optimize_mode: str = 'maximize', all_checkpoint_dir: Incomplete | None = None, population_size: int = 10, factor: float = 0.2, resample_probability: float = 0.25, fraction: float = 0.2) -> None: ...
    random_state: Incomplete
    def update_search_space(self, search_space) -> None:
        """
        Get search space

        Parameters
        ----------
        search_space : dict
            Search space
        """
    def generate_multiple_parameters(self, parameter_id_list, **kwargs):
        """
        Returns multiple sets of trial (hyper-)parameters, as iterable of serializable objects.

        Parameters
        ----------
        parameter_id_list : list of int
            Unique identifiers for each set of requested hyper-parameters.
            These will later be used in :meth:`receive_trial_result`.
        **kwargs
            Used for send_trial_callback.

        Returns
        -------
        list
            A list of newly generated configurations
        """
    def generate_parameters(self, parameter_id, **kwargs):
        """
        Generate parameters, if no trial configration for now, self.credit plus 1 to send the config later

        Parameters
        ----------
        parameter_id : int
            Unique identifier for requested hyper-parameters.
            This will later be used in :meth:`receive_trial_result`.
        **kwargs
            Not used

        Returns
        -------
        dict
            One newly generated configuration

        """
    def receive_trial_result(self, parameter_id, parameters, value, **kwargs) -> None:
        """
        Receive trial's result. if the number of finished trials equals ``self.population_size``, start the next epoch to
        train the model.

        Parameters
        ----------
        parameter_id : int
            Unique identifier of used hyper-parameters, same with :meth:`generate_parameters`.
        parameters : dict
            Hyper-parameters generated by :meth:`generate_parameters`.
        value : dict
            Result from trial (the return value of :func:`nni.report_final_result`).
        """
    def trial_end(self, parameter_id, success, **kwargs) -> None:
        """
        Deal with trial failure

        Parameters
        ----------
        parameter_id : int
            Unique identifier for hyper-parameters used by this trial.
        success : bool
            True if the trial successfully completed; False if failed or terminated.
        **kwargs
            Unstable parameters which should be ignored by normal users.
        """
    def import_data(self, data):
        """
        Parameters
        ----------
        data : json obj
            imported data records

        Returns
        -------
        int
            the start epoch number after data imported, only used for unittest
        """
