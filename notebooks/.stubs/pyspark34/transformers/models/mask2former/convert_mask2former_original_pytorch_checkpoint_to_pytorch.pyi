from _typeshed import Incomplete
from dataclasses import dataclass
from pathlib import Path
from torch import Tensor, nn as nn
from transformers import Mask2FormerConfig as Mask2FormerConfig, Mask2FormerForUniversalSegmentation as Mask2FormerForUniversalSegmentation, Mask2FormerImageProcessor as Mask2FormerImageProcessor, Mask2FormerModel as Mask2FormerModel, SwinConfig as SwinConfig
from transformers.models.mask2former.modeling_mask2former import Mask2FormerForUniversalSegmentationOutput as Mask2FormerForUniversalSegmentationOutput, Mask2FormerModelOutput as Mask2FormerModelOutput
from transformers.utils import logging as logging
from typing import Any, Dict, Iterator, List, Tuple

StateDict = Dict[str, Tensor]
logger: Incomplete

class TrackedStateDict:
    to_track: Incomplete
    def __init__(self, to_track: Dict) -> None:
        '''This class "tracks" a python dictionary by keeping track of which item is accessed.

        Args:
            to_track (Dict): The dictionary we wish to track
        '''
    def __getitem__(self, key: str) -> Any: ...
    def __setitem__(self, key: str, item: Any): ...
    def diff(self) -> List[str]:
        """This method returns a set difference between the keys in the tracked state dict and the one we have access so far.
        This is an effective method to check if we have update all the keys

        Returns:
            List[str]: List of keys not yet updated
        """
    def copy(self) -> Dict: ...

def prepare_img(): ...

@dataclass
class Args:
    """Fake command line arguments needed by mask2former/detectron implementation"""
    config_file: str
    def __init__(self, config_file) -> None: ...

def setup_cfg(args: Args): ...

class OriginalMask2FormerConfigToOursConverter:
    def __call__(self, original_config: object) -> Mask2FormerConfig: ...

class OriginalMask2FormerConfigToFeatureExtractorConverter:
    def __call__(self, original_config: object) -> Mask2FormerImageProcessor: ...

class OriginalMask2FormerCheckpointToOursConverter:
    original_model: Incomplete
    config: Incomplete
    def __init__(self, original_model: nn.Module, config: Mask2FormerConfig) -> None: ...
    def pop_all(self, renamed_keys: List[Tuple[str, str]], dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_maskformer_swin_backbone(self, dst_state_dict: StateDict, src_state_dict: StateDict, config: Mask2FormerConfig): ...
    def replace_swin_backbone(self, dst_state_dict: StateDict, src_state_dict: StateDict, config: Mask2FormerConfig): ...
    def replace_pixel_module(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def rename_keys_in_masked_attention_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_masked_attention_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_keys_qkv_transformer_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_transformer_module(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_universal_segmentation_module(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def convert(self, mask2former: Mask2FormerModel) -> Mask2FormerModel: ...
    def convert_universal_segmentation(self, mask2former: Mask2FormerForUniversalSegmentation) -> Mask2FormerForUniversalSegmentation: ...
    @staticmethod
    def using_dirs(checkpoints_dir: Path, config_dir: Path) -> Iterator[Tuple[object, Path, Path]]: ...

def test(original_model, our_model: Mask2FormerForUniversalSegmentation, feature_extractor: Mask2FormerImageProcessor, tolerance: float): ...
def get_model_name(checkpoint_file: Path): ...
