from _typeshed import Incomplete
from pathlib import Path
from torch import nn
from transformers import MarianConfig as MarianConfig, MarianMTModel as MarianMTModel, MarianTokenizer as MarianTokenizer
from typing import Dict, List, Union

def remove_suffix(text: str, suffix: str): ...
def remove_prefix(text: str, prefix: str): ...
def convert_encoder_layer(opus_dict, layer_prefix: str, converter: dict): ...
def load_layers_(layer_lst: nn.ModuleList, opus_state: dict, converter, is_decoder: bool = False): ...
def find_pretrained_model(src_lang: str, tgt_lang: str) -> List[str]:
    """Find models that can accept src_lang as input and return tgt_lang as output."""
def add_emb_entries(wemb, final_bias, n_special_tokens: int = 1): ...
def cast_marian_config(raw_cfg: Dict[str, str]) -> Dict: ...

CONFIG_KEY: str

def load_config_from_state_dict(opus_dict): ...
def find_model_file(dest_dir): ...

ROM_GROUP: str
GROUPS: Incomplete
GROUP_TO_OPUS_NAME: Incomplete
OPUS_GITHUB_URL: str
ORG_NAME: str

def convert_opus_name_to_hf_name(x):
    """For OPUS-MT-Train/ DEPRECATED"""
def convert_hf_name_to_opus_name(hf_model_name):
    """
    Relies on the assumption that there are no language codes like pt_br in models that are not in GROUP_TO_OPUS_NAME.
    """
def get_system_metadata(repo_root): ...

FRONT_MATTER_TEMPLATE: str
DEFAULT_REPO: str
DEFAULT_MODEL_DIR: Incomplete

def write_model_card(hf_model_name: str, repo_root=..., save_dir=..., dry_run: bool = False, extra_metadata={}) -> str:
    """
    Copy the most recent model's readme section from opus, and add metadata. upload command: aws s3 sync model_card_dir
    s3://models.huggingface.co/bert/Helsinki-NLP/ --dryrun
    """
def make_registry(repo_path: str = 'Opus-MT-train/models'): ...
def convert_all_sentencepiece_models(model_list: Incomplete | None = None, repo_path: Incomplete | None = None, dest_dir=...):
    """Requires 300GB"""
def lmap(f, x) -> List: ...
def fetch_test_set(test_set_url): ...
def convert_whole_dir(path=...) -> None: ...
def save_tokenizer_config(dest_dir: Path, separate_vocabs: bool = False): ...
def add_to_vocab_(vocab: Dict[str, int], special_tokens: List[str]): ...
def find_vocab_file(model_dir): ...
def find_src_vocab_file(model_dir): ...
def find_tgt_vocab_file(model_dir): ...
def add_special_tokens_to_vocab(model_dir: Path, separate_vocab: bool = False) -> None: ...
def check_equal(marian_cfg, k1, k2) -> None: ...
def check_marian_cfg_assumptions(marian_cfg) -> None: ...

BIAS_KEY: str
BART_CONVERTER: Incomplete

class OpusState:
    state_dict: Incomplete
    share_encoder_decoder_embeddings: Incomplete
    source_dir: Incomplete
    tokenizer: Incomplete
    pad_token_id: Incomplete
    state_keys: Incomplete
    cfg: Incomplete
    hf_config: Incomplete
    def __init__(self, source_dir, eos_token_id: int = 0) -> None: ...
    @property
    def extra_keys(self): ...
    def sub_keys(self, layer_prefix): ...
    def load_tokenizer(self): ...
    def load_marian_model(self) -> MarianMTModel: ...

def download_and_unzip(url, dest_dir) -> None: ...
def convert(source_dir: Path, dest_dir): ...
def load_yaml(path): ...
def save_json(content: Union[Dict, List], path: str) -> None: ...
def unzip(zip_path: str, dest_dir: str) -> None: ...
