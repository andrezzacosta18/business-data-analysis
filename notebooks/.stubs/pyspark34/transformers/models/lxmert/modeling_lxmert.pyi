import torch
from ...activations import ACT2FN as ACT2FN, gelu as gelu
from ...modeling_utils import PreTrainedModel as PreTrainedModel
from ...utils import ModelOutput as ModelOutput, add_code_sample_docstrings as add_code_sample_docstrings, add_start_docstrings as add_start_docstrings, add_start_docstrings_to_model_forward as add_start_docstrings_to_model_forward, logging as logging, replace_return_docstrings as replace_return_docstrings
from .configuration_lxmert import LxmertConfig as LxmertConfig
from _typeshed import Incomplete
from dataclasses import dataclass
from torch import nn
from typing import Dict, Optional, Tuple, Union

logger: Incomplete
LXMERT_PRETRAINED_MODEL_ARCHIVE_LIST: Incomplete

class GeLU(nn.Module):
    def __init__(self) -> None: ...
    def forward(self, x): ...

@dataclass
class LxmertModelOutput(ModelOutput):
    '''
    Lxmert\'s outputs that contain the last hidden states, pooled outputs, and attention probabilities for the language,
    visual, and, cross-modality encoders. (note: the visual encoder in Lxmert is referred to as the "relation-ship"
    encoder")


    Args:
        language_output (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):
            Sequence of hidden-states at the output of the last layer of the language encoder.
        vision_output (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):
            Sequence of hidden-states at the output of the last layer of the visual encoder.
        pooled_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`):
            Last layer hidden-state of the first token of the sequence (classification, CLS, token) further processed
            by a Linear layer and a Tanh activation function. The Linear
        language_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):
            Tuple of `torch.FloatTensor` (one for input features + one for the output of each cross-modality layer) of
            shape `(batch_size, sequence_length, hidden_size)`.
        vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):
            Tuple of `torch.FloatTensor` (one for input features + one for the output of each cross-modality layer) of
            shape `(batch_size, sequence_length, hidden_size)`.
        language_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
        vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
        cross_encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
    '''
    language_output: Optional[torch.FloatTensor] = ...
    vision_output: Optional[torch.FloatTensor] = ...
    pooled_output: Optional[torch.FloatTensor] = ...
    language_hidden_states: Optional[Tuple[torch.FloatTensor]] = ...
    vision_hidden_states: Optional[Tuple[torch.FloatTensor]] = ...
    language_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    vision_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    cross_encoder_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    def __init__(self, language_output, vision_output, pooled_output, language_hidden_states, vision_hidden_states, language_attentions, vision_attentions, cross_encoder_attentions) -> None: ...

@dataclass
class LxmertForQuestionAnsweringOutput(ModelOutput):
    """
    Output type of [`LxmertForQuestionAnswering`].

    Args:
        loss (*optional*, returned when `labels` is provided, `torch.FloatTensor` of shape `(1,)`):
            Total loss as the sum of the masked language modeling loss and the next sequence prediction
            (classification) loss.k.
        question_answering_score: (`torch.FloatTensor` of shape `(batch_size, n_qa_answers)`, *optional*):
            Prediction scores of question answering objective (classification).
        language_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):
            Tuple of `torch.FloatTensor` (one for input features + one for the output of each cross-modality layer) of
            shape `(batch_size, sequence_length, hidden_size)`.
        vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):
            Tuple of `torch.FloatTensor` (one for input features + one for the output of each cross-modality layer) of
            shape `(batch_size, sequence_length, hidden_size)`.
        language_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
        vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
        cross_encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
    """
    loss: Optional[torch.FloatTensor] = ...
    question_answering_score: Optional[torch.FloatTensor] = ...
    language_hidden_states: Optional[Tuple[torch.FloatTensor]] = ...
    vision_hidden_states: Optional[Tuple[torch.FloatTensor]] = ...
    language_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    vision_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    cross_encoder_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    def __init__(self, loss, question_answering_score, language_hidden_states, vision_hidden_states, language_attentions, vision_attentions, cross_encoder_attentions) -> None: ...

@dataclass
class LxmertForPreTrainingOutput(ModelOutput):
    """
    Output type of [`LxmertForPreTraining`].

    Args:
        loss (*optional*, returned when `labels` is provided, `torch.FloatTensor` of shape `(1,)`):
            Total loss as the sum of the masked language modeling loss and the next sequence prediction
            (classification) loss.
        prediction_logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):
            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).
        cross_relationship_score: (`torch.FloatTensor` of shape `(batch_size, 2)`):
            Prediction scores of the textual matching objective (classification) head (scores of True/False
            continuation before SoftMax).
        question_answering_score: (`torch.FloatTensor` of shape `(batch_size, n_qa_answers)`):
            Prediction scores of question answering objective (classification).
        language_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):
            Tuple of `torch.FloatTensor` (one for input features + one for the output of each cross-modality layer) of
            shape `(batch_size, sequence_length, hidden_size)`.
        vision_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):
            Tuple of `torch.FloatTensor` (one for input features + one for the output of each cross-modality layer) of
            shape `(batch_size, sequence_length, hidden_size)`.
        language_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
        vision_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.
        cross_encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):
            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,
            sequence_length)`. Attentions weights after the attention softmax, used to compute the weighted average in
            the self-attention heads.

    """
    loss: Optional[torch.FloatTensor] = ...
    prediction_logits: Optional[torch.FloatTensor] = ...
    cross_relationship_score: Optional[torch.FloatTensor] = ...
    question_answering_score: Optional[torch.FloatTensor] = ...
    language_hidden_states: Optional[Tuple[torch.FloatTensor]] = ...
    vision_hidden_states: Optional[Tuple[torch.FloatTensor]] = ...
    language_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    vision_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    cross_encoder_attentions: Optional[Tuple[torch.FloatTensor]] = ...
    def __init__(self, loss, prediction_logits, cross_relationship_score, question_answering_score, language_hidden_states, vision_hidden_states, language_attentions, vision_attentions, cross_encoder_attentions) -> None: ...

def load_tf_weights_in_lxmert(model, config, tf_checkpoint_path):
    """Load tf checkpoints in a pytorch model."""

class LxmertEmbeddings(nn.Module):
    """Construct the embeddings from word, position and token_type embeddings."""
    word_embeddings: Incomplete
    position_embeddings: Incomplete
    token_type_embeddings: Incomplete
    LayerNorm: Incomplete
    dropout: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, input_ids, token_type_ids: Incomplete | None = None, inputs_embeds: Incomplete | None = None): ...

class LxmertAttention(nn.Module):
    num_attention_heads: Incomplete
    attention_head_size: Incomplete
    head_size: Incomplete
    query: Incomplete
    key: Incomplete
    value: Incomplete
    dropout: Incomplete
    def __init__(self, config, ctx_dim: Incomplete | None = None) -> None: ...
    def transpose_for_scores(self, x): ...
    def forward(self, hidden_states, context, attention_mask: Incomplete | None = None, output_attentions: bool = False): ...

class LxmertAttentionOutput(nn.Module):
    dense: Incomplete
    LayerNorm: Incomplete
    dropout: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states, input_tensor): ...

class LxmertCrossAttentionLayer(nn.Module):
    att: Incomplete
    output: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, input_tensor, ctx_tensor, ctx_att_mask: Incomplete | None = None, output_attentions: bool = False): ...

class LxmertSelfAttentionLayer(nn.Module):
    self: Incomplete
    output: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, input_tensor, attention_mask, output_attentions: bool = False): ...

class LxmertIntermediate(nn.Module):
    dense: Incomplete
    intermediate_act_fn: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states): ...

class LxmertOutput(nn.Module):
    dense: Incomplete
    LayerNorm: Incomplete
    dropout: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states, input_tensor): ...

class LxmertLayer(nn.Module):
    attention: Incomplete
    intermediate: Incomplete
    output: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states, attention_mask: Incomplete | None = None, output_attentions: bool = False): ...

class LxmertXLayer(nn.Module):
    visual_attention: Incomplete
    lang_self_att: Incomplete
    visn_self_att: Incomplete
    lang_inter: Incomplete
    lang_output: Incomplete
    visn_inter: Incomplete
    visn_output: Incomplete
    def __init__(self, config) -> None: ...
    def cross_att(self, lang_input, lang_attention_mask, visual_input, visual_attention_mask, output_x_attentions: bool = False): ...
    def self_att(self, lang_input, lang_attention_mask, visual_input, visual_attention_mask): ...
    def output_fc(self, lang_input, visual_input): ...
    def forward(self, lang_feats, lang_attention_mask, visual_feats, visual_attention_mask, output_attentions: bool = False): ...

class LxmertVisualFeatureEncoder(nn.Module):
    visn_fc: Incomplete
    visn_layer_norm: Incomplete
    box_fc: Incomplete
    box_layer_norm: Incomplete
    dropout: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, visual_feats, visual_pos): ...

class LxmertEncoder(nn.Module):
    visn_fc: Incomplete
    config: Incomplete
    num_l_layers: Incomplete
    num_x_layers: Incomplete
    num_r_layers: Incomplete
    layer: Incomplete
    x_layers: Incomplete
    r_layers: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, lang_feats, lang_attention_mask, visual_feats, visual_pos, visual_attention_mask: Incomplete | None = None, output_attentions: Incomplete | None = None): ...

class LxmertPooler(nn.Module):
    dense: Incomplete
    activation: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states): ...

class LxmertPredictionHeadTransform(nn.Module):
    dense: Incomplete
    transform_act_fn: Incomplete
    LayerNorm: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states): ...

class LxmertLMPredictionHead(nn.Module):
    transform: Incomplete
    decoder: Incomplete
    bias: Incomplete
    def __init__(self, config, lxmert_model_embedding_weights) -> None: ...
    def forward(self, hidden_states): ...

class LxmertVisualAnswerHead(nn.Module):
    logit_fc: Incomplete
    def __init__(self, config, num_labels) -> None: ...
    def forward(self, hidden_states): ...

class LxmertVisualObjHead(nn.Module):
    transform: Incomplete
    visual_losses: Incomplete
    decoder_dict: Incomplete
    def __init__(self, config) -> None: ...
    def forward(self, hidden_states): ...

class LxmertPreTrainingHeads(nn.Module):
    predictions: Incomplete
    seq_relationship: Incomplete
    def __init__(self, config, lxmert_model_embedding_weights) -> None: ...
    def forward(self, sequence_output, pooled_output): ...

class LxmertPreTrainedModel(PreTrainedModel):
    """
    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained
    models.
    """
    config_class = LxmertConfig
    load_tf_weights = load_tf_weights_in_lxmert
    base_model_prefix: str

LXMERT_START_DOCSTRING: str
LXMERT_INPUTS_DOCSTRING: str

class LxmertModel(LxmertPreTrainedModel):
    embeddings: Incomplete
    encoder: Incomplete
    pooler: Incomplete
    def __init__(self, config) -> None: ...
    def get_input_embeddings(self): ...
    def set_input_embeddings(self, new_embeddings) -> None: ...
    def forward(self, input_ids: Optional[torch.LongTensor] = None, visual_feats: Optional[torch.FloatTensor] = None, visual_pos: Optional[torch.FloatTensor] = None, attention_mask: Optional[torch.FloatTensor] = None, visual_attention_mask: Optional[torch.FloatTensor] = None, token_type_ids: Optional[torch.LongTensor] = None, inputs_embeds: Optional[torch.FloatTensor] = None, output_attentions: Optional[bool] = None, output_hidden_states: Optional[bool] = None, return_dict: Optional[bool] = None) -> Union[LxmertModelOutput, Tuple[torch.FloatTensor]]: ...

class LxmertForPreTraining(LxmertPreTrainedModel):
    config: Incomplete
    num_qa_labels: Incomplete
    visual_loss_normalizer: Incomplete
    task_mask_lm: Incomplete
    task_obj_predict: Incomplete
    task_matched: Incomplete
    task_qa: Incomplete
    lxmert: Incomplete
    cls: Incomplete
    obj_predict_head: Incomplete
    answer_head: Incomplete
    loss_fcts: Incomplete
    visual_losses: Incomplete
    def __init__(self, config) -> None: ...
    def resize_num_qa_labels(self, num_labels):
        """
        Build a resized question answering linear layer Module from a provided new linear layer. Increasing the size
        will add newly initialized weights. Reducing the size will remove weights from the end

        Args:
            num_labels (`int`, *optional*):
                New number of labels in the linear layer weight matrix. Increasing the size will add newly initialized
                weights at the end. Reducing the size will remove weights from the end. If not provided or `None`, just
                returns a pointer to the qa labels ``torch.nn.Linear``` module of the model without doing anything.

        Return:
            `torch.nn.Linear`: Pointer to the resized Linear layer or the old Linear layer
        """
    def get_qa_logit_layer(self) -> nn.Module:
        """
        Returns the linear layer that produces question answering logits.

        Returns:
            `nn.Module`: A torch module mapping the question answering prediction hidden states or `None` if LXMERT
            does not have a visual answering head.
        """
    def forward(self, input_ids: Optional[torch.LongTensor] = None, visual_feats: Optional[torch.FloatTensor] = None, visual_pos: Optional[torch.FloatTensor] = None, attention_mask: Optional[torch.FloatTensor] = None, visual_attention_mask: Optional[torch.FloatTensor] = None, token_type_ids: Optional[torch.LongTensor] = None, inputs_embeds: Optional[torch.FloatTensor] = None, labels: Optional[torch.LongTensor] = None, obj_labels: Optional[Dict[str, Tuple[torch.FloatTensor, torch.FloatTensor]]] = None, matched_label: Optional[torch.LongTensor] = None, ans: Optional[torch.Tensor] = None, output_attentions: Optional[bool] = None, output_hidden_states: Optional[bool] = None, return_dict: Optional[bool] = None, **kwargs) -> Union[LxmertForPreTrainingOutput, Tuple[torch.FloatTensor]]:
        """
        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):
            Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,
            config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the
            loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`
        obj_labels: (`Dict[Str: Tuple[Torch.FloatTensor, Torch.FloatTensor]]`, *optional*):
            each key is named after each one of the visual losses and each element of the tuple is of the shape
            `(batch_size, num_features)` and `(batch_size, num_features, visual_feature_dim)` for each the label id and
            the label score respectively
        matched_label (`torch.LongTensor` of shape `(batch_size,)`, *optional*):
            Labels for computing the whether or not the text input matches the image (classification) loss. Input
            should be a sequence pair (see `input_ids` docstring) Indices should be in `[0, 1]`:

            - 0 indicates that the sentence does not match the image,
            - 1 indicates that the sentence does match the image.
        ans (`Torch.Tensor` of shape `(batch_size)`, *optional*):
            a one hot representation hof the correct answer *optional*

        Returns:
        """

class LxmertForQuestionAnswering(LxmertPreTrainedModel):
    config: Incomplete
    num_qa_labels: Incomplete
    visual_loss_normalizer: Incomplete
    lxmert: Incomplete
    answer_head: Incomplete
    loss: Incomplete
    def __init__(self, config) -> None: ...
    def resize_num_qa_labels(self, num_labels):
        """
        Build a resized question answering linear layer Module from a provided new linear layer. Increasing the size
        will add newly initialized weights. Reducing the size will remove weights from the end

        Args:
            num_labels (`int`, *optional*):
                New number of labels in the linear layer weight matrix. Increasing the size will add newly initialized
                weights at the end. Reducing the size will remove weights from the end. If not provided or `None`, just
                returns a pointer to the qa labels ``torch.nn.Linear``` module of the model without doing anything.

        Return:
            `torch.nn.Linear`: Pointer to the resized Linear layer or the old Linear layer
        """
    def get_qa_logit_layer(self) -> nn.Module:
        """
        Returns the linear layer that produces question answering logits

        Returns:
            `nn.Module`: A torch module mapping the question answering prediction hidden states. `None`: A NoneType
            object if Lxmert does not have the visual answering head.
        """
    def forward(self, input_ids: Optional[torch.LongTensor] = None, visual_feats: Optional[torch.FloatTensor] = None, visual_pos: Optional[torch.FloatTensor] = None, attention_mask: Optional[torch.FloatTensor] = None, visual_attention_mask: Optional[torch.FloatTensor] = None, token_type_ids: Optional[torch.LongTensor] = None, inputs_embeds: Optional[torch.FloatTensor] = None, labels: Optional[torch.Tensor] = None, output_attentions: Optional[bool] = None, output_hidden_states: Optional[bool] = None, return_dict: Optional[bool] = None) -> Union[LxmertForQuestionAnsweringOutput, Tuple[torch.FloatTensor]]:
        """
        labels: (`Torch.Tensor` of shape `(batch_size)`, *optional*):
            A one-hot representation of the correct answer
        """
