from _typeshed import Incomplete
from dataclasses import dataclass
from pathlib import Path
from torch import Tensor, nn as nn
from transformers.models.maskformer.feature_extraction_maskformer import MaskFormerFeatureExtractor as MaskFormerFeatureExtractor
from transformers.models.maskformer.modeling_maskformer import MaskFormerConfig as MaskFormerConfig, MaskFormerForInstanceSegmentation as MaskFormerForInstanceSegmentation, MaskFormerForInstanceSegmentationOutput as MaskFormerForInstanceSegmentationOutput, MaskFormerModel as MaskFormerModel, MaskFormerModelOutput as MaskFormerModelOutput
from transformers.utils import logging as logging
from typing import Any, Dict, Iterator, List, Tuple

StateDict = Dict[str, Tensor]
logger: Incomplete

class TrackedStateDict:
    to_track: Incomplete
    def __init__(self, to_track: Dict) -> None:
        '''This class "tracks" a python dictionary by keeping track of which item is accessed.

        Args:
            to_track (Dict): The dictionary we wish to track
        '''
    def __getitem__(self, key: str) -> Any: ...
    def __setitem__(self, key: str, item: Any): ...
    def diff(self) -> List[str]:
        """This method returns a set difference between the keys in the tracked state dict and the one we have access so far.
        This is an effective method to check if we have update all the keys

        Returns:
            List[str]: List of keys not yet updated
        """
    def copy(self) -> Dict: ...

def prepare_img(): ...

@dataclass
class Args:
    """Fake command line arguments needed by maskformer/detectron implementation"""
    config_file: str
    def __init__(self, config_file) -> None: ...

def setup_cfg(args: Args): ...

class OriginalMaskFormerConfigToOursConverter:
    def __call__(self, original_config: object) -> MaskFormerConfig: ...

class OriginalMaskFormerConfigToFeatureExtractorConverter:
    def __call__(self, original_config: object) -> MaskFormerFeatureExtractor: ...

class OriginalMaskFormerCheckpointToOursConverter:
    original_model: Incomplete
    config: Incomplete
    def __init__(self, original_model: nn.Module, config: MaskFormerConfig) -> None: ...
    def pop_all(self, renamed_keys: List[Tuple[str, str]], dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_backbone(self, dst_state_dict: StateDict, src_state_dict: StateDict, config: MaskFormerConfig): ...
    def replace_pixel_module(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def rename_keys_in_detr_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_q_k_v_in_detr_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_detr_decoder(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_transformer_module(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def replace_instance_segmentation_module(self, dst_state_dict: StateDict, src_state_dict: StateDict): ...
    def convert(self, mask_former: MaskFormerModel) -> MaskFormerModel: ...
    def convert_instance_segmentation(self, mask_former: MaskFormerForInstanceSegmentation) -> MaskFormerForInstanceSegmentation: ...
    @staticmethod
    def using_dirs(checkpoints_dir: Path, config_dir: Path) -> Iterator[Tuple[object, Path, Path]]: ...

def test(original_model, our_model: MaskFormerForInstanceSegmentation, feature_extractor: MaskFormerFeatureExtractor): ...
def get_name(checkpoint_file: Path): ...
