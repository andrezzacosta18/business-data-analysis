from ...models.bert import BasicTokenizer as BasicTokenizer
from ...utils import logging as logging
from _typeshed import Incomplete

logger: Incomplete

def normalize_answer(s):
    """Lower text and remove punctuation, articles and extra whitespace."""
def get_tokens(s): ...
def compute_exact(a_gold, a_pred): ...
def compute_f1(a_gold, a_pred): ...
def get_raw_scores(examples, preds):
    """
    Computes the exact and f1 scores from the examples and the model predictions
    """
def apply_no_ans_threshold(scores, na_probs, qid_to_has_ans, na_prob_thresh): ...
def make_eval_dict(exact_scores, f1_scores, qid_list: Incomplete | None = None): ...
def merge_eval(main_eval, new_eval, prefix) -> None: ...
def find_best_thresh_v2(preds, scores, na_probs, qid_to_has_ans): ...
def find_all_best_thresh_v2(main_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans) -> None: ...
def find_best_thresh(preds, scores, na_probs, qid_to_has_ans): ...
def find_all_best_thresh(main_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans) -> None: ...
def squad_evaluate(examples, preds, no_answer_probs: Incomplete | None = None, no_answer_probability_threshold: float = 1.0): ...
def get_final_text(pred_text, orig_text, do_lower_case, verbose_logging: bool = False):
    """Project the tokenized prediction back to the original text."""
def compute_predictions_logits(all_examples, all_features, all_results, n_best_size, max_answer_length, do_lower_case, output_prediction_file, output_nbest_file, output_null_log_odds_file, verbose_logging, version_2_with_negative, null_score_diff_threshold, tokenizer):
    """Write final predictions to the json file and log-odds of null if needed."""
def compute_predictions_log_probs(all_examples, all_features, all_results, n_best_size, max_answer_length, output_prediction_file, output_nbest_file, output_null_log_odds_file, start_n_top, end_n_top, version_2_with_negative, tokenizer, verbose_logging):
    """
    XLNet write prediction logic (more complex than Bert's). Write final predictions to the json file and log-odds of
    null if needed.

    Requires utils_squad_evaluate.py
    """
