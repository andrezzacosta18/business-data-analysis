import pandas
import pyspark.sql.connect.plan as plan
from _typeshed import Incomplete
from pyspark._globals import _NoValueType
from pyspark.errors import PySparkAttributeError as PySparkAttributeError, PySparkTypeError as PySparkTypeError
from pyspark.errors.exceptions.connect import SparkConnectException as SparkConnectException
from pyspark.rdd import PythonEvalType as PythonEvalType
from pyspark.sql.connect._typing import ArrowMapIterFunction as ArrowMapIterFunction, ColumnOrName as ColumnOrName, LiteralType as LiteralType, OptionalPrimitiveType as OptionalPrimitiveType, PandasMapIterFunction as PandasMapIterFunction, PrimitiveType as PrimitiveType
from pyspark.sql.connect.column import Column as Column
from pyspark.sql.connect.expressions import UnresolvedRegex as UnresolvedRegex
from pyspark.sql.connect.functions import col as col, lit as lit
from pyspark.sql.connect.group import GroupedData as GroupedData
from pyspark.sql.connect.readwriter import DataFrameWriter as DataFrameWriter, DataFrameWriterV2 as DataFrameWriterV2
from pyspark.sql.connect.session import SparkSession as SparkSession
from pyspark.sql.connect.types import from_arrow_schema as from_arrow_schema
from pyspark.sql.connect.utils import check_dependencies as check_dependencies
from pyspark.sql.observation import Observation as Observation
from pyspark.sql.types import Row as Row, StructType as StructType
from pyspark.storagelevel import StorageLevel as StorageLevel
from typing import Any, Callable, Dict, Iterator, List, Tuple, overload

class DataFrame:
    def __init__(self, session: SparkSession, schema: StructType | None = None) -> None:
        """Creates a new data frame"""
    @property
    def write(self) -> DataFrameWriter: ...
    def isEmpty(self) -> bool: ...
    def select(self, *cols: ColumnOrName) -> DataFrame: ...
    def selectExpr(self, *expr: str | List[str]) -> DataFrame: ...
    def agg(self, *exprs: Column | Dict[str, str]) -> DataFrame: ...
    def alias(self, alias: str) -> DataFrame: ...
    def colRegex(self, colName: str) -> Column: ...
    @property
    def dtypes(self) -> List[Tuple[str, str]]: ...
    @property
    def columns(self) -> List[str]: ...
    @property
    def sparkSession(self) -> SparkSession: ...
    def count(self) -> int: ...
    def crossJoin(self, other: DataFrame) -> DataFrame: ...
    def coalesce(self, numPartitions: int) -> DataFrame: ...
    @overload
    def repartition(self, numPartitions: int, *cols: ColumnOrName) -> DataFrame: ...
    @overload
    def repartition(self, *cols: ColumnOrName) -> DataFrame: ...
    @overload
    def repartitionByRange(self, numPartitions: int, *cols: ColumnOrName) -> DataFrame: ...
    @overload
    def repartitionByRange(self, *cols: ColumnOrName) -> DataFrame: ...
    def dropDuplicates(self, subset: List[str] | None = None) -> DataFrame: ...
    drop_duplicates = dropDuplicates
    def distinct(self) -> DataFrame: ...
    def drop(self, *cols: ColumnOrName) -> DataFrame: ...
    def filter(self, condition: Column | str) -> DataFrame: ...
    def first(self) -> Row | None: ...
    def groupBy(self, *cols: ColumnOrName) -> GroupedData: ...
    groupby = groupBy
    def rollup(self, *cols: ColumnOrName) -> GroupedData: ...
    def cube(self, *cols: ColumnOrName) -> GroupedData: ...
    @overload
    def head(self) -> Row | None: ...
    @overload
    def head(self, n: int) -> List[Row]: ...
    def take(self, num: int) -> List[Row]: ...
    def join(self, other: DataFrame, on: str | List[str] | Column | List[Column] | None = None, how: str | None = None) -> DataFrame: ...
    def limit(self, n: int) -> DataFrame: ...
    def tail(self, num: int) -> List[Row]: ...
    def sort(self, *cols: str | Column | List[str | Column], **kwargs: Any) -> DataFrame: ...
    orderBy = sort
    def sortWithinPartitions(self, *cols: str | Column | List[str | Column], **kwargs: Any) -> DataFrame: ...
    def sample(self, withReplacement: float | bool | None = None, fraction: int | float | None = None, seed: int | None = None) -> DataFrame: ...
    def withColumnRenamed(self, existing: str, new: str) -> DataFrame: ...
    def withColumnsRenamed(self, colsMap: Dict[str, str]) -> DataFrame: ...
    def withColumns(self, colsMap: Dict[str, Column]) -> DataFrame: ...
    def withColumn(self, colName: str, col: Column) -> DataFrame: ...
    def withMetadata(self, columnName: str, metadata: Dict[str, Any]) -> DataFrame: ...
    def unpivot(self, ids: ColumnOrName | List['ColumnOrName'] | Tuple['ColumnOrName', ...], values: ColumnOrName | List['ColumnOrName'] | Tuple['ColumnOrName', ...] | None, variableColumnName: str, valueColumnName: str) -> DataFrame: ...
    melt = unpivot
    def hint(self, name: str, *parameters: PrimitiveType | List['PrimitiveType']) -> DataFrame: ...
    def randomSplit(self, weights: List[float], seed: int | None = None) -> List['DataFrame']: ...
    def observe(self, observation: Observation | str, *exprs: Column) -> DataFrame: ...
    def show(self, n: int = 20, truncate: bool | int = True, vertical: bool = False) -> None: ...
    def union(self, other: DataFrame) -> DataFrame: ...
    def unionAll(self, other: DataFrame) -> DataFrame: ...
    def unionByName(self, other: DataFrame, allowMissingColumns: bool = False) -> DataFrame: ...
    def subtract(self, other: DataFrame) -> DataFrame: ...
    def exceptAll(self, other: DataFrame) -> DataFrame: ...
    def intersect(self, other: DataFrame) -> DataFrame: ...
    def intersectAll(self, other: DataFrame) -> DataFrame: ...
    def where(self, condition: Column | str) -> DataFrame: ...
    @property
    def na(self) -> DataFrameNaFunctions: ...
    def fillna(self, value: LiteralType | Dict[str, 'LiteralType'], subset: str | Tuple[str, ...] | List[str] | None = None) -> DataFrame: ...
    def dropna(self, how: str = 'any', thresh: int | None = None, subset: str | Tuple[str, ...] | List[str] | None = None) -> DataFrame: ...
    def replace(self, to_replace: LiteralType | List['LiteralType'] | Dict['LiteralType', 'OptionalPrimitiveType'], value: OptionalPrimitiveType | List['OptionalPrimitiveType'] | _NoValueType | None = ..., subset: List[str] | None = None) -> DataFrame: ...
    @property
    def stat(self) -> DataFrameStatFunctions: ...
    def summary(self, *statistics: str) -> DataFrame: ...
    def describe(self, *cols: str | List[str]) -> DataFrame: ...
    def cov(self, col1: str, col2: str) -> float: ...
    def corr(self, col1: str, col2: str, method: str | None = None) -> float: ...
    def approxQuantile(self, col: str | List[str] | Tuple[str], probabilities: List[float] | Tuple[float], relativeError: float) -> List[float] | List[List[float]]: ...
    def crosstab(self, col1: str, col2: str) -> DataFrame: ...
    def freqItems(self, cols: List[str] | Tuple[str], support: float | None = None) -> DataFrame: ...
    def sampleBy(self, col: ColumnOrName, fractions: Dict[Any, float], seed: int | None = None) -> DataFrame: ...
    def __getattr__(self, name: str) -> Column: ...
    @overload
    def __getitem__(self, item: int | str) -> Column: ...
    @overload
    def __getitem__(self, item: Column | List | Tuple) -> DataFrame: ...
    def collect(self) -> List[Row]: ...
    def toPandas(self) -> pandas.DataFrame: ...
    @property
    def schema(self) -> StructType: ...
    def isLocal(self) -> bool: ...
    @property
    def isStreaming(self) -> bool: ...
    def printSchema(self) -> None: ...
    def inputFiles(self) -> List[str]: ...
    def to(self, schema: StructType) -> DataFrame: ...
    def toDF(self, *cols: str) -> DataFrame: ...
    def transform(self, func: Callable[..., 'DataFrame'], *args: Any, **kwargs: Any) -> DataFrame: ...
    def explain(self, extended: bool | str | None = None, mode: str | None = None) -> None: ...
    def createTempView(self, name: str) -> None: ...
    def createOrReplaceTempView(self, name: str) -> None: ...
    def createGlobalTempView(self, name: str) -> None: ...
    def createOrReplaceGlobalTempView(self, name: str) -> None: ...
    def rdd(self, *args: Any, **kwargs: Any) -> None: ...
    def cache(self) -> DataFrame: ...
    def persist(self, storageLevel: StorageLevel = ...) -> DataFrame: ...
    @property
    def storageLevel(self) -> StorageLevel: ...
    def unpersist(self, blocking: bool = False) -> DataFrame: ...
    @property
    def is_cached(self) -> bool: ...
    def withWatermark(self, *args: Any, **kwargs: Any) -> None: ...
    def foreach(self, *args: Any, **kwargs: Any) -> None: ...
    def foreachPartition(self, *args: Any, **kwargs: Any) -> None: ...
    def toLocalIterator(self, prefetchPartitions: bool = False) -> Iterator[Row]: ...
    def checkpoint(self, *args: Any, **kwargs: Any) -> None: ...
    def localCheckpoint(self, *args: Any, **kwargs: Any) -> None: ...
    def to_pandas_on_spark(self, *args: Any, **kwargs: Any) -> None: ...
    def pandas_api(self, *args: Any, **kwargs: Any) -> None: ...
    def registerTempTable(self, name: str) -> None: ...
    def mapInPandas(self, func: PandasMapIterFunction, schema: StructType | str) -> DataFrame: ...
    def mapInArrow(self, func: ArrowMapIterFunction, schema: StructType | str) -> DataFrame: ...
    def writeStream(self, *args: Any, **kwargs: Any) -> None: ...
    def toJSON(self, *args: Any, **kwargs: Any) -> None: ...
    def sameSemantics(self, other: DataFrame) -> bool: ...
    def semanticHash(self) -> int: ...
    def writeTo(self, table: str) -> DataFrameWriterV2: ...
    def offset(self, n: int) -> DataFrame:
        """Returns a new :class: `DataFrame` by skipping the first `n` rows.

        .. versionadded:: 3.4.0

        Parameters
        ----------
        num : int
            Number of records to skip.

        Returns
        -------
        :class:`DataFrame`
            Subset of the records
        """
    @classmethod
    def withPlan(cls, plan: plan.LogicalPlan, session: SparkSession) -> DataFrame:
        """
        Main initialization method used to construct a new data frame with a child plan.
        This is for internal purpose.
        """

class DataFrameNaFunctions:
    df: Incomplete
    def __init__(self, df: DataFrame) -> None: ...
    def fill(self, value: LiteralType | Dict[str, 'LiteralType'], subset: str | Tuple[str, ...] | List[str] | None = None) -> DataFrame: ...
    def drop(self, how: str = 'any', thresh: int | None = None, subset: str | Tuple[str, ...] | List[str] | None = None) -> DataFrame: ...
    def replace(self, to_replace: List['LiteralType'] | Dict['LiteralType', 'OptionalPrimitiveType'], value: OptionalPrimitiveType | List['OptionalPrimitiveType'] | _NoValueType | None = ..., subset: List[str] | None = None) -> DataFrame: ...

class DataFrameStatFunctions:
    df: Incomplete
    def __init__(self, df: DataFrame) -> None: ...
    def cov(self, col1: str, col2: str) -> float: ...
    def corr(self, col1: str, col2: str, method: str | None = None) -> float: ...
    def approxQuantile(self, col: str | List[str] | Tuple[str], probabilities: List[float] | Tuple[float], relativeError: float) -> List[float] | List[List[float]]: ...
    def crosstab(self, col1: str, col2: str) -> DataFrame: ...
    def freqItems(self, cols: List[str] | Tuple[str], support: float | None = None) -> DataFrame: ...
    def sampleBy(self, col: str, fractions: Dict[Any, float], seed: int | None = None) -> DataFrame: ...
