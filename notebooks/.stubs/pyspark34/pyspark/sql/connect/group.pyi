from pyspark.rdd import PythonEvalType as PythonEvalType
from pyspark.sql.connect._typing import GroupedMapPandasUserDefinedFunction as GroupedMapPandasUserDefinedFunction, LiteralType as LiteralType, PandasCogroupedMapFunction as PandasCogroupedMapFunction, PandasGroupedMapFunction as PandasGroupedMapFunction
from pyspark.sql.connect.column import Column as Column
from pyspark.sql.connect.dataframe import DataFrame as DataFrame
from pyspark.sql.connect.functions import col as col, lit as lit
from pyspark.sql.connect.utils import check_dependencies as check_dependencies
from pyspark.sql.types import NumericType as NumericType, StructType as StructType
from typing import Any, Dict, List, Sequence, overload

class GroupedData:
    def __init__(self, df: DataFrame, group_type: str, grouping_cols: Sequence['Column'], pivot_col: Column | None = None, pivot_values: Sequence['LiteralType'] | None = None) -> None: ...
    @overload
    def agg(self, *exprs: Column) -> DataFrame: ...
    @overload
    def agg(self, __exprs: Dict[str, str]) -> DataFrame: ...
    def min(self, *cols: str) -> DataFrame: ...
    def max(self, *cols: str) -> DataFrame: ...
    def sum(self, *cols: str) -> DataFrame: ...
    def avg(self, *cols: str) -> DataFrame: ...
    mean = avg
    def count(self) -> DataFrame: ...
    def pivot(self, pivot_col: str, values: List['LiteralType'] | None = None) -> GroupedData: ...
    def apply(self, udf: GroupedMapPandasUserDefinedFunction) -> DataFrame: ...
    def applyInPandas(self, func: PandasGroupedMapFunction, schema: StructType | str) -> DataFrame: ...
    def applyInPandasWithState(self, *args: Any, **kwargs: Any) -> None: ...
    def cogroup(self, other: GroupedData) -> PandasCogroupedOps: ...

class PandasCogroupedOps:
    def __init__(self, gd1: GroupedData, gd2: GroupedData) -> None: ...
    def applyInPandas(self, func: PandasCogroupedMapFunction, schema: StructType | str) -> DataFrame: ...
