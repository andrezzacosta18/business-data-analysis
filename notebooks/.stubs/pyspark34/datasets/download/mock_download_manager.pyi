from ..utils.file_utils import cached_path as cached_path, hf_github_url as hf_github_url
from ..utils.logging import get_logger as get_logger
from ..utils.version import Version as Version
from _typeshed import Incomplete
from collections.abc import Generator
from typing import Callable, List

logger: Incomplete

class MockDownloadManager:
    dummy_file_name: str
    datasets_scripts_dir: str
    is_streaming: bool
    downloaded_size: int
    dataset_name: Incomplete
    cache_dir: Incomplete
    use_local_dummy_data: Incomplete
    config: Incomplete
    download_callbacks: Incomplete
    load_existing_dummy_data: Incomplete
    version_name: Incomplete
    def __init__(self, dataset_name: str, config: str, version: Version | str, cache_dir: str | None = None, use_local_dummy_data: bool = False, load_existing_dummy_data: bool = True, download_callbacks: List[Callable] | None = None) -> None: ...
    @property
    def dummy_file(self): ...
    @property
    def dummy_data_folder(self): ...
    @property
    def dummy_zip_file(self): ...
    def download_dummy_data(self): ...
    @property
    def local_path_to_dummy_data(self): ...
    @property
    def github_path_to_dummy_data(self): ...
    @property
    def manual_dir(self): ...
    def download_and_extract(self, data_url, *args): ...
    def download(self, data_url, *args): ...
    def download_custom(self, data_url, custom_download): ...
    def extract(self, path, *args, **kwargs): ...
    def get_recorded_sizes_checksums(self): ...
    def create_dummy_data_dict(self, path_to_dummy_data, data_url): ...
    def create_dummy_data_list(self, path_to_dummy_data, data_url): ...
    def create_dummy_data_single(self, path_to_dummy_data, data_url): ...
    def delete_extracted_files(self) -> None: ...
    def manage_extracted_files(self) -> None: ...
    def iter_archive(self, path) -> Generator[Incomplete, None, None]: ...
    def iter_files(self, paths) -> Generator[Incomplete, None, None]: ...
