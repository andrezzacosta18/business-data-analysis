import torch
from _typeshed import Incomplete
from collections.abc import Generator
from dataclasses import dataclass
from torch._guards import Source as Source
from torch._ops import OpOverload as OpOverload
from torch._prims_common import ELEMENTWISE_TYPE_PROMOTION_KIND as ELEMENTWISE_TYPE_PROMOTION_KIND, elementwise_dtypes as elementwise_dtypes, is_float_dtype as is_float_dtype, is_integer_dtype as is_integer_dtype
from torch._subclasses.meta_utils import MetaConverter as MetaConverter
from torch.fx.operator_schemas import normalize_function as normalize_function
from torch.multiprocessing.reductions import StorageWeakRef as StorageWeakRef
from torch.overrides import TorchFunctionMode as TorchFunctionMode
from torch.utils._mode_utils import no_dispatch as no_dispatch
from torch.utils._python_dispatch import TorchDispatchMode as TorchDispatchMode
from torch.utils._pytree import PyTree as PyTree, tree_flatten as tree_flatten, tree_map as tree_map, tree_map_only as tree_map_only
from torch.utils._stats import count as count, count_label as count_label
from torch.utils.weak import WeakIdRef as WeakIdRef
from typing import Any, Callable, Dict, List, Type, TypeVar
from weakref import ReferenceType

log: Incomplete
pytree: Incomplete
T = TypeVar('T')
TensorWeakRef = Any
aten: Incomplete
CONSTANT_NUMEL_LIMIT: int
RECURSION_COUNT: int

class IncrementRecursionCount:
    def __init__(self) -> None: ...
    def __del__(self) -> None: ...

@dataclass
class UnsupportedFakeTensorException(RuntimeError):
    reason: str
    def __init__(self, reason) -> None: ...

@dataclass
class DynamicOutputShapeException(RuntimeError):
    func: OpOverload
    def __init__(self, func) -> None: ...

@dataclass
class DataDependentOutputException(RuntimeError):
    func: OpOverload
    def __init__(self, func) -> None: ...

def contains_tensor_types(type): ...
def get_schema_info(func): ...
def torch_decomp_decompositions(func): ...
def tree_flatten_only(ty: Type[T], pytree: PyTree): ...

class FakeTensorConverter:
    @property
    def tensor_memo(self): ...
    meta_converter: MetaConverter
    constant_storage_mapping: Dict[StorageWeakRef, List[ReferenceType]]
    def __init__(self) -> None: ...
    def add_constant_storage_mapping(self, fake_tensor) -> None: ...
    def invalidate_constant_aliases(self, tensor) -> None: ...
    def set_tensor_memo(self, t, v) -> None: ...
    def from_real_tensor(self, fake_mode, t, make_constant: bool = False, shape_env: Incomplete | None = None, ignore_subclass: bool = False, *, source: Incomplete | None = None): ...
    def from_meta_and_device(self, fake_mode, t, device): ...
    def __call__(self, fake_mode, t, *, make_constant: bool = False, shape_env: Incomplete | None = None, ignore_subclass: bool = False, source: Incomplete | None = None): ...

op_implementations: Incomplete

def register_op_impl(run_impl_check: Callable[[OpOverload], bool] | OpOverload): ...
def constructors(fake_mode, func, *args, **kwargs): ...
def non_kwarg_to(fake_mode, func, *args, **kwargs): ...
def resize_as_(fake_mode, func, *args, **kwargs): ...
def dyn_shape(fake_mode, func, *args, **kwargs) -> None: ...
def local_scalar_dense(fake_mode, func, arg): ...
def data_dep(fake_mode, func, *args, **kwargs) -> None: ...
def check_no_bool_index_tensors(func, self, indices) -> None: ...
def run_and_return_new_tensor_of_input_device(fake_mode, func, args, kwargs): ...
def index_tensor(fake_mode, func, *args, **kwargs): ...
def index_put(fake_mode, func, *args, **kwargs): ...
def index_put_(fake_mode, func, *args, **kwargs): ...
def nyi(fake_mode, func, *args, **kwargs) -> None: ...
def conv(fake_mode, func, *args, **kwargs): ...

FAST_OP_IMPLEMENTATIONS: Incomplete

def register_fast_op_impl(func: OpOverload): ...
def infer_size(a, b): ...
def make_fast_binary_impl(slow_ref): ...
def get_fast_op_impls(): ...
def in_kernel_invocation_manager(fake_mode) -> Generator[None, None, None]: ...
def should_allow_numbers_as_tensors(func: OpOverload): ...

class FakeTensorConfig:
    debug: Incomplete

class FakeTensor(torch.Tensor):
    """
    Meta tensors give you the ability to run PyTorch code without having to
    actually do computation through tensors allocated on a `meta` device.
    Because the device is `meta`, meta tensors do not model device propagation.
    FakeTensor extends MetaTensors to also carry an additional `fake_device`
    which tracks devices that would have been used.
    """
    fake_device: torch.device
    fake_mode: FakeTensorMode
    constant: torch.Tensor | None
    @property
    def device(self): ...
    @staticmethod
    def __new__(cls, fake_mode, elem, device, constant: Incomplete | None = None): ...
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def from_tensor(t, fake_mode): ...
    @classmethod
    def __torch_dispatch__(cls, func, types, args=(), kwargs: Incomplete | None = None): ...
    __torch_function__: Incomplete

class FakeTensorMode(TorchDispatchMode):
    allow_fallback_kernels: Incomplete
    fake_tensor_converter: Incomplete
    allow_meta: Incomplete
    allow_non_fake_inputs: Incomplete
    in_kernel_invocation: bool
    shape_env: Incomplete
    def __init__(self, *, allow_fallback_kernels: bool = True, allow_non_fake_inputs: bool = False, shape_env: Incomplete | None = None) -> None: ...
    def __torch_dispatch__(self, func, types, args=(), kwargs: Incomplete | None = None): ...
    def dispatch(self, func, types, args=(), kwargs: Incomplete | None = None): ...
    def check_for_subclass(self, args, kwargs): ...
    def validate_and_convert_non_fake_tensors(self, func, converter, args, kwargs):
        """
        Checks if the list of tensors are fake tensors.
        If not, try to convert them to fake tensors.
        """
    def wrap_meta_outputs_with_default_device_logic(self, r, func, args, kwargs): ...
    def gen_wrap_fn(self, func, args, kwargs): ...
    def cpp_meta_supports_symint(self, func): ...
    @property
    def lift_fns(self): ...
    def may_turn_const(self, t): ...
    def invalidate_written_to_constants(self, func, flat_arg_fake_tensors, args, kwargs) -> None: ...
    def from_tensor(self, tensor, static_shapes: bool = False, ignore_subclass: bool = False, source: Source | None = None): ...

def run_fallback_kernel(fake_mode, func, args, kwargs, orig_not_implemented_exception): ...

class FakeCopyMode(TorchFunctionMode):
    fake_mode: Incomplete
    def __init__(self, fake_mode) -> None: ...
    def __torch_function__(self, func, types, args=(), kwargs: Incomplete | None = None): ...
