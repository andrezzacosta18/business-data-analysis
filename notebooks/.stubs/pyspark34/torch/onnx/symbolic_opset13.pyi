from _typeshed import Incomplete
from torch.onnx import errors as errors, symbolic_helper as symbolic_helper, utils as utils
from torch.onnx._internal import jit_utils as jit_utils, registration as registration

def softmax(g: jit_utils.GraphContext, input, dim, dtype: Incomplete | None = None): ...
def log_softmax(g: jit_utils.GraphContext, input, dim, dtype: Incomplete | None = None): ...
def frobenius_norm(g: jit_utils.GraphContext, self, dim: Incomplete | None = None, keepdim: bool = False): ...
def split(g: jit_utils.GraphContext, self, split_size_or_sizes, dim, _outputs: Incomplete | None = None): ...
def split_with_sizes(g: jit_utils.GraphContext, self, split_sizes, dim, _outputs: Incomplete | None = None): ...
def unsafe_split(g: jit_utils.GraphContext, self, split_size_or_sizes, dim, _outputs: Incomplete | None = None): ...
def unsafe_split_with_sizes(g: jit_utils.GraphContext, self, split_sizes, dim, _outputs: Incomplete | None = None): ...
def tensor_split(g: jit_utils.GraphContext, self, indices_or_sections, dim, _outputs: Incomplete | None = None): ...
def unbind(g: jit_utils.GraphContext, self, dim: int = 0, _outputs: Incomplete | None = None): ...
def nonzero_numpy(g: jit_utils.GraphContext, input, _outputs: Incomplete | None = None): ...
def where(g: jit_utils.GraphContext, condition, self: Incomplete | None = None, other: Incomplete | None = None, _outputs: Incomplete | None = None): ...
def fake_quantize_per_channel_affine(g: jit_utils.GraphContext, inputs, scale, zero_point, axis, quant_min: int = -128, quant_max: int = 127): ...
def fake_quantize_per_tensor_affine(g: jit_utils.GraphContext, inputs, scale, zero_point, quant_min: int = -128, quant_max: int = 127): ...
def unsafe_chunk(g: jit_utils.GraphContext, self, chunks, dim, _outputs: Incomplete | None = None): ...
def repeat_interleave(g: jit_utils.GraphContext, self, repeats, dim: Incomplete | None = None, output_size: Incomplete | None = None): ...
def diagonal(g: jit_utils.GraphContext, self, offset, dim1, dim2): ...
def quantized_linear(g: jit_utils.GraphContext, q_input, q_weight, bias, op_scale, op_zero_point): ...
def quantized_conv2d(g: jit_utils.GraphContext, q_input, q_weight, bias, stride, padding, dilation, groups, op_scale, op_zero_point): ...
def quantized_conv2d_relu(g: jit_utils.GraphContext, q_input, q_weight, bias, stride, padding, dilation, groups, op_scale, op_zero_point): ...
