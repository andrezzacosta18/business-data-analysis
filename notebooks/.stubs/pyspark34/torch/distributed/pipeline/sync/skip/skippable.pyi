from .namespace import Namespace
from _typeshed import Incomplete
from torch import Tensor, nn
from typing import Any, Callable, ClassVar, FrozenSet, Generator, Iterable, List, Sequence, Tuple, Type, TypeVar

__all__ = ['skippable', 'stash', 'pop', 'verify_skippables']

Tensors = Sequence[Tensor]
TensorOrTensors = Tensor | Tensors
StashPopGenerator = Generator[StashPop, Tensor | None, TensorOrTensors]
T = TypeVar('T', bound='Skippable')

class Skippable(nn.Module):
    """The base class for skippable modules.

    Do not use this class directly. Define a subclass by :func:`skippable`
    instead.

    """
    module_cls: ClassVar[Type[SkippableModule]]
    stashable_names: ClassVar[FrozenSet[str]]
    poppable_names: ClassVar[FrozenSet[str]]
    module: Incomplete
    namespaces: Incomplete
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def namespaced(self, name: str) -> Tuple[Namespace, str]:
        """Prepends namespace for the given skip name."""
    def stashable(self) -> Iterable[Tuple[Namespace, str]]:
        """Iterates over namespaced skip names to be stashed."""
    def poppable(self) -> Iterable[Tuple[Namespace, str]]:
        """Iterates over namespaced skip names to be popped."""
    def isolate(self, ns: Namespace, *, only: Iterable[str] | None = None) -> T:
        """Isolates a specified subset or the whole set of skip tensors into a
        namespace. In a single sequential module, skip tensors with the same
        name are not allowed unless they are isolated by different namespaces.

        Here's an example using the same name for skip tensors twice. Each pair
        of ``Layer1`` and ``Layer2`` is isolated with its own namespace ``ns1``
        and ``ns2``. There is no conflict anymore::

            ns1 = Namespace()
            ns2 = Namespace()

            model = nn.Sequential(
                Layer1().isolate(ns1),
                Layer1().isolate(ns2),
                Layer2(),
                Layer3().isolate(ns2),
                Layer3().isolate(ns1),
            )

        When `only` parameter is omitted, all skip tensors are isolated. You
        can isolate a subset of skip tensors by passing `only` parameter::

            ns_alice = Namespace()
            ns_bob = Namespace()

            model = nn.Sequential(
                ...
                StashStashPop().isolate(ns_alice, only=['alice']) \\\n                               .isolate(ns_bob, only=['bob']),
                ...
            )

        Args:
            ns (Namespace):
                namespace for isolation

        Keyword Args:
            only (iterable of strs):
                names of specific skip tensors to be isolated (omit this option
                to isolate all skip tensors declared in this module)

        Returns:
            this module itself

        """
    def dispatch(self, input, handle_stash: Callable[[str, Tensor | None], None], handle_pop: Callable[[str], Tensor | None]):
        """Dispatches :class:`stash` or :class:`pop` commands generated by the
        module's ``forward()``.
        """
    def forward(self, input: List[Any] | Tensor) -> TensorOrTensors:
        """Performs the forward propagation. :class:`stash` or :class:`pop`
        commands will be handled by portals silently. The portals won't be
        exposed to users.

        Raises:
            RuntimeError:
                illegal 'stash' or 'pop' is found.

        """

def skippable(stash: Iterable[str] = (), pop: Iterable[str] = ()) -> Callable[[Type[SkippableModule]], Type[Skippable]]:
    '''The decorator to define a :class:`nn.Module <torch.nn.Module>` with skip
    connections. Decorated modules are called "skippable". This functionality
    works perfectly fine even when the module is not wrapped by
    :class:`~torch.distributed.pipeline.sync.Pipe`.

    Each skip tensor is managed by its name. Before manipulating skip tensors,
    a skippable module must statically declare the names for skip tensors by
    `stash` and/or `pop` parameters. Skip tensors with pre-declared name can be
    stashed by ``yield stash(name, tensor)`` or popped by ``tensor = yield
    pop(name)``.

    Here is an example with three layers. A skip tensor named "1to3" is stashed
    and popped at the first and last layer, respectively::

        @skippable(stash=[\'1to3\'])
        class Layer1(nn.Module):
            def forward(self, input):
                yield stash(\'1to3\', input)
                return f1(input)

        class Layer2(nn.Module):
            def forward(self, input):
                return f2(input)

        @skippable(pop=[\'1to3\'])
        class Layer3(nn.Module):
            def forward(self, input):
                skip_1to3 = yield pop(\'1to3\')
                return f3(input) + skip_1to3

        model = nn.Sequential(Layer1(), Layer2(), Layer3())

    One skippable module can stash or pop multiple skip tensors::

        @skippable(stash=[\'alice\', \'bob\'], pop=[\'carol\'])
        class StashStashPop(nn.Module):
            def forward(self, input):
                yield stash(\'alice\', f_alice(input))
                yield stash(\'bob\', f_bob(input))
                carol = yield pop(\'carol\')
                return input + carol

    Every skip tensor must be associated with exactly one pair of `stash` and
    `pop`. :class:`~torch.distributed.pipeline.sync.Pipe` checks this
    restriction automatically when wrapping a module. You can also check the
    restriction by :func:`verify_skippables`
    without :class:`~torch.distributed.pipeline.sync.Pipe`.

    '''

class stash:
    """The command to stash a skip tensor.

    ::

        def forward(self, input):
            yield stash('name', input)
            return f(input)

    Args:
        name (str): name of skip tensor
        input (torch.Tensor or None): tensor to pass to the skip connection

    """
    name: Incomplete
    tensor: Incomplete
    def __init__(self, name: str, tensor: Tensor | None) -> None: ...

class pop:
    """The command to pop a skip tensor.

    ::

        def forward(self, input):
            skip = yield pop('name')
            return f(input) + skip

    Args:
        name (str): name of skip tensor

    Returns:
        the skip tensor previously stashed by another layer under the same name

    """
    name: Incomplete
    def __init__(self, name: str) -> None: ...

def verify_skippables(module: nn.Sequential) -> None:
    '''Verifies if the underlying skippable modules satisfy integrity.

    Every skip tensor must have only one pair of `stash` and `pop`. If there
    are one or more unmatched pairs, it will raise :exc:`TypeError` with the
    detailed messages.

    Here are a few failure cases. :func:`verify_skippables` will report failure
    for these cases::

        # Layer1 stashes "1to3".
        # Layer3 pops "1to3".

        nn.Sequential(Layer1(), Layer2())
        #               └──── ?

        nn.Sequential(Layer2(), Layer3())
        #                   ? ────┘

        nn.Sequential(Layer1(), Layer2(), Layer3(), Layer3())
        #               └───────────────────┘       ^^^^^^

        nn.Sequential(Layer1(), Layer1(), Layer2(), Layer3())
        #             ^^^^^^      └───────────────────┘

    To use the same name for multiple skip tensors, they must be isolated by
    different namespaces. See :meth:`isolate()
    <torchpipe.skip.skippable.Skippable.isolate>`.

    Raises:
        TypeError:
            one or more pairs of `stash` and `pop` are not matched.

    '''
