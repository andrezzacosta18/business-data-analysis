import torch.nn as nn
from _typeshed import Incomplete
from torch.distributed._shard.sharded_tensor import ShardedTensor as ShardedTensor

class SimpleMegatronLM(nn.Module):
    fc1: Incomplete
    gelu: Incomplete
    fc2: Incomplete
    def __init__(self, linear_size, rank: Incomplete | None = None, dtype=...) -> None: ...
    def forward(self, inp): ...
    def get_weights(self): ...
    def get_biases(self): ...
    def get_weight_grads(self): ...
    def get_bias_grads(self): ...
