import torch
import torch.nn as nn
from _typeshed import Incomplete
from torch.cuda.amp import GradScaler as GradScaler, autocast as autocast
from torch.distributed.distributed_c10d import AllreduceOptions as AllreduceOptions, GroupMember as GroupMember, get_world_size as get_world_size
from torch.nn.parallel import DistributedDataParallel as DistributedDataParallel
from torch.testing._internal.common_distributed import DistTestCases as DistTestCases, MultiProcessTestCase as MultiProcessTestCase, TEST_SKIPS as TEST_SKIPS, captured_output as captured_output, cleanup_temp_dir as cleanup_temp_dir, init_multigpu_helper as init_multigpu_helper, initialize_temp_directories as initialize_temp_directories, nccl_skip_if_lt_x_gpu as nccl_skip_if_lt_x_gpu, require_n_gpus_for_nccl_backend as require_n_gpus_for_nccl_backend, requires_nccl_version as requires_nccl_version, simple_sparse_reduce_tests as simple_sparse_reduce_tests, skip_if_lt_x_gpu as skip_if_lt_x_gpu, skip_if_no_gpu as skip_if_no_gpu, skip_if_odd_worldsize as skip_if_odd_worldsize, skip_if_rocm as skip_if_rocm, skip_if_small_worldsize as skip_if_small_worldsize, verify_ddp_error_logged as verify_ddp_error_logged, with_dist_debug_levels as with_dist_debug_levels, with_nccl_blocking_wait as with_nccl_blocking_wait
from torch.testing._internal.common_utils import FILE_SCHEMA as FILE_SCHEMA, IS_FBCODE as IS_FBCODE, IS_MACOS as IS_MACOS, IS_SANDCASTLE as IS_SANDCASTLE, IS_WINDOWS as IS_WINDOWS, NO_MULTIPROCESSING_SPAWN as NO_MULTIPROCESSING_SPAWN, instantiate_parametrized_tests as instantiate_parametrized_tests, parametrize as parametrize, sandcastle_skip as sandcastle_skip, sandcastle_skip_if as sandcastle_skip_if
from torch.utils.data.distributed import DistributedSampler as DistributedSampler
from typing import Any, Callable, NamedTuple

HAS_TORCHVISION: bool

class NetWithBuffers(nn.Module):
    a: Incomplete
    b: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class Foo:
    x: Incomplete
    def __init__(self, x) -> None: ...
    def __eq__(self, other): ...

f: Incomplete
foo_cpu_tensor: Incomplete
COLLECTIVES_OBJECT_TEST_LIST: Incomplete
PROFILING_SUPPORTED_BACKENDS: Incomplete
CUDA_PROFILING_SUPPORTED_BACKENDS: Incomplete
SEND_RECV_PROFILING_SUPPORTED_BACKENDS: Incomplete
EXPECTED_FIELDS: Incomplete
TestNamedTupleInput_0: Incomplete

class TestNamedTupleInput_1(NamedTuple):
    a: torch.tensor
    b: torch.tensor

skipIfNoTorchVision: Incomplete
BACKEND: Incomplete
INIT_METHOD: Incomplete
DEFAULT_TIMEOUT: int
CUSTOMIZED_TIMEOUT: Incomplete

def get_profiling_event(postfix, profiler): ...

ddp_prev_reduction_unfinished_str: str
ddp_recommend_find_unused_params_str: str
ddp_find_unused_params_enabled_str: str
ddp_outputs_not_used_in_loss_str: str
ddp_suggest_debug_mode_str: str

class DDPUnevenTestInput(NamedTuple):
    name: str
    model: nn.Module
    inp: torch.tensor | tuple
    sync_interval: int
    throw_on_early_termination: bool = ...
    hook: Callable = ...
    state: Any = ...

class _FC2(nn.Module):
    fc: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class Net(nn.Module):
    fc1: Incomplete
    fc2: Incomplete
    fc3: Incomplete
    relu: Incomplete
    no_grad_param: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class LargeNet(nn.Module):
    fc1: Incomplete
    fc2: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class Task(nn.Module):
    p: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class BatchNormNet(nn.Module):
    fc1: Incomplete
    bn: Incomplete
    fc2: Incomplete
    def __init__(self, affine: bool = True) -> None: ...
    def forward(self, x): ...

class UnusedParamTwoLinLayerNet(nn.Module):
    a: Incomplete
    b: Incomplete
    c: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class DictOutputModule(nn.Module):
    module: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class TwoLinLayerNet(nn.Module):
    a: Incomplete
    b: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

class EmbeddingNetDifferentParams(nn.Module):
    """
    A module containing an embedding with different dimension or different # of
    parameters depending on the rank.
    """
    embedding: Incomplete
    lin: Incomplete
    lin2: Incomplete
    def __init__(self, rank, diff_num_params: bool = False) -> None: ...
    def forward(self, x): ...

class ControlFlowToyModel(nn.Module):
    lin1: Incomplete
    lin2: Incomplete
    def __init__(self) -> None: ...
    def forward(self, x): ...

DDP_NET: Incomplete
BN_NET: Incomplete
BN_NET_NO_AFFINE: Incomplete
ONLY_SBN_NET: Incomplete

def get_timeout(test_id): ...

default_pg_timeout: int
CUSTOM_PG_TIMEOUT: Incomplete

def require_backend(backends): ...
def require_backends_available(backends): ...
def require_world_size(world_size): ...

class Barrier:
    barrier_id: int
    @classmethod
    def init(cls) -> None: ...
    @classmethod
    def sync(cls, wait_for: Incomplete | None = None, timeout: int = 10) -> None: ...

class TestDistBackend(MultiProcessTestCase):
    @classmethod
    def setUpClass(cls) -> None: ...
    skip_return_code_checks: Incomplete
    def setUp(self) -> None: ...
    def tearDown(self) -> None: ...
    @property
    def init_method(self): ...
    @property
    def world_size(self): ...

class DistributedTest:
    class _DistTestBase:
        def test_dump_DDP_relevant_env_vars(self): ...
        def test_get_rank(self) -> None: ...
        def test_get_backend(self) -> None: ...
        def test_Backend_enum_class(self) -> None: ...
        def test_destroy_group(self) -> None: ...
        def test_get_rank_size_group(self) -> None: ...
        def test_destroy_full_group(self) -> None: ...
        def test_get_rank_size_full_group(self) -> None: ...
        def test_barrier_timeout_global(self) -> None: ...
        def test_barrier_timeout_group(self) -> None: ...
        def test_barrier_timeout_full_group(self) -> None: ...
        def test_backend_group(self) -> None: ...
        def test_backend_full_group(self) -> None: ...
        def test_new_subgroups(self) -> None: ...
        def test_new_subgroups_group_size_exceeds_world_size(self) -> None: ...
        def test_new_subgroups_world_size_not_divisible_by_group_size(self) -> None: ...
        def test_new_subgroups_by_enumeration(self) -> None: ...
        def test_new_subgroups_by_enumeration_input_rank_exceeds_world_size(self) -> None: ...
        def test_new_subgroups_by_enumeration_negative_input_rank(self) -> None: ...
        def test_new_subgroups_overlap_not_allowed(self) -> None: ...
        def test_average_parameters(self) -> None: ...
        def test_periodic_model_averager(self) -> None: ...
        def test_periodic_model_averager_param_group(self) -> None: ...
        def test_1_level_hierarchical_model_averager_equivalent_to_periodic_model_averager(self) -> None: ...
        def test_3_level_hierarchical_model_averager(self) -> None: ...
        def test_batch_isend_irecv_nccl(self) -> None: ...
        def test_batch_isend_irecv_ring_exchange_nccl(self) -> None: ...
        def test_batch_isend_irecv_self_nccl(self) -> None: ...
        def test_batch_isend_irecv_no_rank_zero_nccl(self) -> None: ...
        def test_batch_isend_irecv_gloo(self) -> None: ...
        def test_batch_isend_irecv_gloo_tags(self) -> None: ...
        def test_batch_isend_irecv_tensor_err(self) -> None: ...
        def test_batch_isend_irecv_op_err(self) -> None: ...
        def test_batch_isend_irecv_op_list_err(self) -> None: ...
        def test_batch_isend_irecv_mixed_backend_err(self) -> None: ...
        def test_send_recv_nccl(self) -> None: ...
        def test_send_recv_nccl_autograd_profiler(self) -> None: ...
        def test_send_recv_nccl_torch_profiler(self) -> None: ...
        def test_send_recv(self) -> None: ...
        def test_send_recv_autograd_profiler(self) -> None: ...
        def test_send_recv_torch_profiler(self): ...
        def test_send_recv_any_source(self) -> None: ...
        def test_send_recv_any_source_autograd_profiler(self) -> None: ...
        def test_send_recv_any_source_torch_profiler(self): ...
        def test_send_recv_with_tag(self) -> None: ...
        def test_send_recv_with_tag_autograd_profiler(self): ...
        def test_send_recv_with_tag_torch_profiler(self): ...
        def test_isend(self) -> None: ...
        def test_isend_autograd_profiler(self) -> None: ...
        def test_isend_torch_profiler(self) -> None: ...
        def test_irecv(self) -> None: ...
        def test_broadcast(self) -> None: ...
        def test_broadcast_cuda(self) -> None: ...
        def test_broadcast_group(self) -> None: ...
        def test_broadcast_full_group(self) -> None: ...
        def test_nccl_high_priority_stream(self) -> None: ...
        def test_reduce_sum(self) -> None: ...
        def test_reduce_sum_cuda(self) -> None: ...
        def test_reduce_product(self): ...
        def test_reduce_min(self) -> None: ...
        def test_reduce_max(self) -> None: ...
        def test_reduce_group_sum(self) -> None: ...
        def test_reduce_group_product(self): ...
        def test_reduce_group_min(self) -> None: ...
        def test_reduce_group_max(self) -> None: ...
        def test_reduce_full_group_sum(self) -> None: ...
        def test_reduce_full_group_product(self): ...
        def test_reduce_full_group_min(self) -> None: ...
        def test_reduce_full_group_max(self) -> None: ...
        def test_reduce_sum_twice(self) -> None: ...
        def test_reduce_sum_cuda_twice(self) -> None: ...
        def test_reduce_scatter_v_cuda(self) -> None: ...
        def test_reduce_scatter_tensor_cuda(self) -> None: ...
        def test_all_reduce_result_cuda(self) -> None: ...
        def call_dist_op(self, profiling_title_postfix, is_async, op, *args, expect_event: bool = True, secondary_op_call: Incomplete | None = None, profile_cuda: bool = False, tensor_shapes: Incomplete | None = None, **kwargs): ...
        def test_all_reduce_sum(self) -> None: ...
        def test_all_reduce_sum_async(self) -> None: ...
        def test_all_reduce_sum_cuda(self) -> None: ...
        def test_all_reduce_sum_cuda_async(self) -> None: ...
        def test_all_reduce_sum_complex(self) -> None: ...
        def test_all_reduce_complex_unsupported_ops(self) -> None: ...
        def test_all_reduce_sum_cuda_complex(self) -> None: ...
        def test_all_reduce_product(self): ...
        def test_all_reduce_min(self) -> None: ...
        def test_all_reduce_max(self) -> None: ...
        def test_all_reduce_group_sum(self) -> None: ...
        def test_all_reduce_group_product(self): ...
        def test_all_reduce_group_min(self) -> None: ...
        def test_all_reduce_group_max(self) -> None: ...
        def test_all_reduce_full_group_sum(self) -> None: ...
        def test_all_reduce_full_group_product(self): ...
        def test_all_reduce_full_group_min(self) -> None: ...
        def test_all_reduce_full_group_max(self) -> None: ...
        def test_sparse_all_reduce_sum(self): ...
        def test_sparse_all_reduce_sum_cuda(self): ...
        def test_all_reduce_coalesced_max_complex_unsupported(self) -> None: ...
        def test_all_reduce_coalesced_sum(self) -> None: ...
        def test_all_reduce_coalesced_product(self) -> None: ...
        def test_all_reduce_coalesced_min(self) -> None: ...
        def test_all_reduce_coalesced_max(self) -> None: ...
        def test_all_reduce_coalesced_group_sum(self) -> None: ...
        def test_all_reduce_coalesced_group_product(self) -> None: ...
        def test_all_reduce_coalesced_group_min(self) -> None: ...
        def test_all_reduce_coalesced_group_max(self) -> None: ...
        def test_all_reduce_coalesced_full_group_sum(self) -> None: ...
        def test_all_reduce_coalesced_full_group_product(self) -> None: ...
        def test_all_reduce_coalesced_full_group_min(self) -> None: ...
        def test_all_reduce_coalesced_full_group_max(self) -> None: ...
        def test_scatter_checks(self) -> None: ...
        def test_scatter(self) -> None: ...
        def test_scatter_cuda(self) -> None: ...
        def test_scatter_complex(self) -> None: ...
        def test_scatter_cuda_complex(self) -> None: ...
        def test_scatter_group(self) -> None: ...
        def test_scatter_full_group(self) -> None: ...
        def test_gather_checks(self) -> None: ...
        def test_gather(self) -> None: ...
        def test_gather_cuda(self) -> None: ...
        def test_gather_group(self) -> None: ...
        def test_gather_full_group(self) -> None: ...
        def test_all_gather(self) -> None: ...
        def test_all_gather_cuda(self) -> None: ...
        def test_all_gather_complex(self) -> None: ...
        def test_all_gather_cuda_complex(self) -> None: ...
        def test_all_gather_group(self) -> None: ...
        def test_all_gather_full_group(self) -> None: ...
        def test_all_gather_v_cuda(self) -> None: ...
        def test_all_gather_into_cat_tensor_cuda(self) -> None: ...
        def test_all_gather_into_stack_tensor_cuda(self) -> None: ...
        def test_all_gather_coalesced_simple(self) -> None: ...
        def test_all_gather_coalesced_complex(self) -> None: ...
        def test_all_gather_coalesced_group(self) -> None: ...
        def test_all_gather_coalesced_full_group(self) -> None: ...
        def test_all_gather_coalesced_with_empty(self) -> None: ...
        def test_all_to_all_single_equal_split(self) -> None: ...
        def test_all_to_all_single_equal_split_cuda(self) -> None: ...
        def test_all_to_all_single_equal_split_complex(self) -> None: ...
        def test_all_to_all_single_equal_split_cuda_complex(self) -> None: ...
        def test_all_to_all_single_unequal_split(self) -> None: ...
        def test_all_to_all_single_unequal_split_cuda(self) -> None: ...
        def test_all_to_all_single_unequal_split_complex(self) -> None: ...
        def test_all_to_all_single_unequal_split_cuda_complex(self) -> None: ...
        def test_all_to_all(self) -> None: ...
        def test_all_to_all_cuda(self) -> None: ...
        def test_all_to_all_complex(self) -> None: ...
        def test_all_to_all_cuda_complex(self) -> None: ...
        def test_all_to_all_single_equal_split_group(self) -> None: ...
        def test_all_to_all_single_equal_split_group_cuda(self) -> None: ...
        def test_all_to_all_single_unequal_split_group(self) -> None: ...
        def test_all_to_all_single_unequal_split_group_cuda(self) -> None: ...
        def test_all_to_all_group(self) -> None: ...
        def test_all_to_all_group_cuda(self) -> None: ...
        def test_all_to_all_single_equal_split_full_group(self) -> None: ...
        def test_all_to_all_single_equal_split_full_group_cuda(self) -> None: ...
        def test_all_to_all_single_unequal_split_full_group(self) -> None: ...
        def test_all_to_all_single_unequal_split_full_group_cuda(self) -> None: ...
        def test_all_to_all_full_group(self) -> None: ...
        def test_all_to_all_full_group_cuda(self) -> None: ...
        def test_barrier_cuda(self) -> None: ...
        def test_barrier_group_cuda(self) -> None: ...
        def test_barrier_full_group_cuda(self) -> None: ...
        def test_barrier(self) -> None: ...
        def test_barrier_group(self) -> None: ...
        def test_barrier_full_group(self) -> None: ...
        def test_broadcast_multigpu(self) -> None: ...
        def test_all_reduce_multigpu(self) -> None: ...
        def test_all_reduce_multigpu_complex(self) -> None: ...
        def test_reduce_multigpu(self) -> None: ...
        def test_all_gather_multigpu(self) -> None: ...
        def test_all_gather_multigpu_complex(self) -> None: ...
        def test_DistributedDataParallelCPU(self) -> None: ...
        def test_DistributedDataParallelCPU_grad_is_view(self) -> None: ...
        def test_DistributedDataParallel_requires_grad(self): ...
        net1: Incomplete
        relu: Incomplete
        net2: Incomplete
        def test_ddp_zero_output_features(self) -> None: ...
        p: Incomplete
        def test_ddp_create_graph(self): ...
        def test_DistributedDataParallel_non_default_stream(self) -> None: ...
        def test_ddp_comm_hook_logging(self) -> None: ...
        def test_ddp_hook_with_optimizer_parity_adamw(self, grad_as_bucket_view, static_graph, optimize_subset) -> None: ...
        def test_ddp_hook_with_optimizer_parity_adam(self, optimize_subset) -> None: ...
        def test_ddp_hook_with_optimizer_parity_sgd(self, optimize_subset) -> None: ...
        def test_ddp_apply_optim_in_backward(self) -> None: ...
        def test_ddp_apply_optim_in_backward_grad_as_bucket_view_false(self) -> None: ...
        def test_ddp_apply_optim_in_backward_ignored_params(self) -> None: ...
        def test_ddp_hook_parity_allreduce(self) -> None: ...
        def test_ddp_hook_parity_allreduce_process_group(self) -> None: ...
        def test_ddp_hook_parity_powerSGD(self) -> None: ...
        def test_ddp_hook_parity_post_localSGD(self) -> None: ...
        def test_accumulate_gradients_no_sync(self) -> None:
            """
            Runs _test_accumulate_gradients_no_sync using default inputs
            """
        def test_accumulate_gradients_no_sync_grad_is_view(self) -> None:
            """
            Runs _test_accumulate_gradients_no_sync using default inputs
            """
        def test_accumulate_gradients_no_sync_allreduce_hook(self):
            """
            Runs multiple iterations on _test_accumulate_gradients_no_sync
            using allreduce hook and validates whether future result was properly
            passed as gradients in reducer.
            """
        def test_accumulate_gradients_no_sync_allreduce_with_then_hook(self):
            """
            Runs multiple iterations on _test_accumulate_gradients_no_sync using allreduce
            hook that also uses then callbacks. In first then callback result is multiplied
            by 2, and the second callback divides the result by 2 * world_size. It validates
            whether final result was properly passed as gradients in reducer.
            """
        def test_get_future(self): ...
        def test_DistributedDataParallel(self) -> None: ...
        def test_DistributedDataParallel_with_amp_and_grad_is_view(self) -> None: ...
        def test_post_localSGD_optimizer_parity(self) -> None: ...
        def test_post_localSGD_optimizer_parity_grad_is_view(self) -> None: ...
        def test_post_localSGD_optimizer_parity_with_hierarchical_sgd(self) -> None: ...
        def test_post_localSGD_optimizer_parity_with_hierarchical_sgd_grad_is_view(self) -> None: ...
        def test_post_localSGD_optimizer_step_reload(self) -> None: ...
        def test_DistributedDataParallel_SyncBatchNorm_Channels_Last(self) -> None: ...
        def test_DistributedDataParallel_SyncBatchNorm(self) -> None: ...
        def test_DistributedDataParallel_SyncBatchNorm_No_Affine(self) -> None: ...
        def test_DistributedDataParallel_SyncBatchNorm_2D_Input(self) -> None: ...
        def test_DistributedDataParallel_SyncBatchNorm_Single_Input_Per_Process(self) -> None: ...
        def test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_Running_Value(self) -> None: ...
        def test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_gradient(self) -> None: ...
        def test_ddp_logging_data_cpu(self): ...
        def test_ddp_logging_data_gpu(self) -> None: ...
        def test_static_graph_api_cpu(self) -> None: ...
        def test_SyncBatchNorm_process_group(self) -> None: ...
        def test_nccl_backend_bool_allreduce(self) -> None: ...
        def test_nccl_backend_bool_allgather(self) -> None: ...
        def test_nccl_backend_bool_reduce(self) -> None: ...
        def test_nccl_backend_bool_broadcast(self) -> None: ...
        def test_DistributedSampler_padding(self) -> None: ...
        def test_all_gather_object_default_pg(self): ...
        def test_all_gather_object_subgroup(self): ...
        def test_gather_object(self): ...
        def test_gather_object_subgroup(self): ...
        def validate_net_equivalence(self, net) -> None: ...
        def test_ddp_sync_module_states(self) -> None: ...
        def test_ddp_grad_div_uneven_inputs(self) -> None: ...
        def test_ddp_profiling_autograd_profiler(self): ...
        def test_ddp_profiling_torch_profiler(self) -> None: ...
        def test_ddp_join_model_equivalence(self) -> None: ...
        lin: Incomplete
        def test_ddp_uneven_inputs_stop_iteration_sync_bn(self): ...
        t0: Incomplete
        t1: Incomplete
        unused_params_rank: Incomplete
        def test_ddp_uneven_inputs(self): ...
        def test_ddp_uneven_input_join_disable(self) -> None: ...
        param: Incomplete
        def test_ddp_uneven_input_exception(self) -> None: ...
        def test_broadcast_object_list(self): ...
        def test_ddp_ignore_params_arg(self) -> None: ...
        def test_ddp_unused_params_rebuild_buckets_exception(self): ...
        bias: Incomplete
        def test_ddp_shared_grad_acc_unused_params(self): ...
        t: Incomplete
        moved_to_gpu: bool
        def test_ddp_device(self): ...
        def test_ddp_namedtuple(self): ...
        def test_ddp_control_flow_same_across_ranks(self) -> None: ...
        def test_invalid_static_graph(self) -> None: ...
        lin1: Incomplete
        lin2: Incomplete
        rank: Incomplete
        def test_ddp_control_flow_different_across_ranks(self): ...
        def test_scatter_object_list(self) -> None: ...
        def test_compute_bucket_assignment_by_size_sparse_error_without_logger(self) -> None: ...
        def test_compute_bucket_assignment_by_size_sparse_error_with_logger(self) -> None: ...
        def test_verify_model_across_rank_with_logger(self) -> None: ...
        def test_verify_model_across_rank_without_logger(self) -> None: ...
        def test_ddp_model_diff_shape_across_ranks(self) -> None: ...
        def test_ddp_model_diff_num_params_across_ranks(self) -> None: ...
        def test_output_unused_in_loss_tuple_module(self) -> None: ...
        def test_output_unused_in_loss_dict_module(self) -> None: ...
        def test_undefined_grad_parity_unused_parameters(self) -> None: ...
        def test_different_graph_across_ranks(self) -> None: ...
        def test_monitored_barrier_gloo(self) -> None: ...
        def test_monitored_barrier_gloo_subgroup(self) -> None: ...
        def test_monitored_barrier_allreduce_hang(self) -> None: ...
        def test_monitored_barrier_allreduce_hang_wait_all_ranks(self) -> None: ...
        def test_monitored_barrier_gloo_rank_0_timeout(self) -> None: ...
        def test_monitored_barrier_failure_order(self) -> None: ...
        def test_monitored_barrier_wait_all_ranks(self) -> None: ...
        def test_ddp_build_debug_param_to_name_mapping(self) -> None: ...
        def test_ddp_build_debug_param_to_name_mapping_requires_grad(self): ...
        def test_ddp_multiple_nested_unused_params_error(self) -> None: ...
        def test_ddp_multiple_nested_unused_params_err_ignore_params(self) -> None: ...
        def test_ddp_inference(self) -> None: ...
        def test_ddp_sync_bn_training_vs_eval(self) -> None: ...
        def test_ddp_python_error_logged(self) -> None: ...
        def test_ddp_static_graph_nested_types(self): ...
        fc1: Incomplete
        fc2: Incomplete
        def test_ddp_returns_tensor_with_no_grad(self): ...
        def test_detect_ddp_is_actually_static(self): ...
        def test_ddp_new_tensor_in_fwd(self): ...
        def test_ddp_new_tensor_in_fwd_static_graph(self): ...
        def test_ddp_buffer_hook_allreduce_return_future(self) -> None: ...
        def test_ddp_buffer_hook_allreduce(self) -> None: ...
        def test_ddp_broadcast_buffer_via_hook(self) -> None: ...
        a: Incomplete
        b: Incomplete
        def test_ddp_broadcast_buffer(self): ...
        def test_sync_bn_logged(self) -> None: ...
        l1: Incomplete
        def test_stateless_api_with_ddp(self): ...
        fc: Incomplete
        def test_ddp_forward_backward_hook(self): ...
        def test_ddp_hook_pickling_powerSGD(self) -> None: ...
