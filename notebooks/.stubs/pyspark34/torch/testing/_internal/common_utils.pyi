import expecttest
import io
import torch
import unittest
from .composite_compliance import no_dispatch as no_dispatch
from _typeshed import Incomplete
from collections.abc import Generator
from enum import Enum
from pathlib import Path
from torch import Tensor as Tensor
from torch._C import ScriptDict as ScriptDict, ScriptList as ScriptList
from torch._utils_internal import get_writable_path as get_writable_path
from torch.nn import ModuleDict as ModuleDict, ModuleList as ModuleList, ParameterDict as ParameterDict, ParameterList as ParameterList, Sequential as Sequential
from torch.onnx import register_custom_op_symbolic as register_custom_op_symbolic, unregister_custom_op_symbolic as unregister_custom_op_symbolic
from torch.testing import make_tensor as make_tensor
from torch.testing._comparison import BooleanPair as BooleanPair, NonePair as NonePair, NumberPair as NumberPair, Pair as Pair, TensorLikePair as TensorLikePair, not_close_error_metas as not_close_error_metas
from torch.testing._internal.common_dtype import get_all_dtypes as get_all_dtypes
from typing import Any, Callable, Iterable, Iterator, List, Tuple, Type, TypeVar

FILE_SCHEMA: str
IS_CI: Incomplete
IS_SANDCASTLE: Incomplete
IS_FBCODE: Incomplete
IS_REMOTE_GPU: Incomplete
RETRY_TEST_CASES: Incomplete
OVERRIDE_FLAKY_SIGNAL: Incomplete
DISABLE_RUNNING_SCRIPT_CHK: Incomplete
DEFAULT_DISABLED_TESTS_FILE: str
DEFAULT_SLOW_TESTS_FILE: str
disabled_tests_dict: Incomplete
slow_tests_dict: Incomplete
NATIVE_DEVICES: Incomplete

class _TestParametrizer:
    """
    Decorator class for parametrizing a test function, yielding a set of new tests spawned
    from the original generic test, each specialized for a specific set of test inputs. For
    example, parametrizing a test across the set of ops will result in a test function per op.

    The decision of how to parametrize / what to parametrize over is intended to be implemented
    by each derived class.

    In the details, the decorator adds a 'parametrize_fn' property to the test function that is called
    during device-specific test instantiation performed in instantiate_device_type_tests(). Because of this,
    there is no need to parametrize over device type, as that is already handled separately.

    If the decorator is applied to a test function that already has a 'parametrize_fn' property, a new
    composite 'parametrize_fn' will be created that generates tests with the product of the parameters
    generated by the old and new parametrize_fns. This allows for convenient composability of decorators.
    """
    def __call__(self, fn): ...

def compose_parametrize_fns(old_parametrize_fn, new_parametrize_fn):
    '''
    Returns a parametrize_fn that parametrizes over the product of the parameters handled
    by the given parametrize_fns. Each given parametrize_fn should each have the signature
    f(test, generic_cls, device_cls).

    The test names will be a combination of the names produced by the parametrize_fns in
    "<new_name>_<old_name>" order. This order is done to match intuition for constructed names
    when composing multiple decorators; the names will be built in top to bottom order when stacking
    parametrization decorators.

    Args:
        old_parametrize_fn (callable) - First parametrize_fn to compose.
        new_parametrize_fn (callable) - Second parametrize_fn to compose.
    '''
def instantiate_parametrized_tests(generic_cls):
    """
    Instantiates tests that have been decorated with a parametrize_fn. This is generally performed by a
    decorator subclass of _TestParametrizer. The generic test will be replaced on the test class by
    parametrized tests with specialized names.

    You can also use it as a class decorator. E.g.

    ```
    @instantiate_parametrized_tests
    class TestFoo(TestCase):
        ...
    ```

    Args:
        generic_cls (class): Generic test class object containing tests (e.g. TestFoo)
    """

class subtest:
    """
    Explicit subtest case for use with test parametrization.
    Allows for explicit naming of individual subtest cases as well as applying
    decorators to the parametrized test.

    Args:
        arg_values (iterable): Iterable of arg values (e.g. range(10)) or
            tuples of arg values (e.g. [(1, 2), (3, 4)]).
        name (str): Optional name to use for the test.
        decorators (iterable): Iterable of decorators to apply to the generated test.
    """
    arg_values: Incomplete
    name: Incomplete
    decorators: Incomplete
    def __init__(self, arg_values, name: Incomplete | None = None, decorators: Incomplete | None = None) -> None: ...

class parametrize(_TestParametrizer):
    '''
    Decorator for applying generic test parametrizations.

    The interface for this decorator is modeled after `@pytest.mark.parametrize`.
    Basic usage between this decorator and pytest\'s is identical. The first argument
    should be a string containing comma-separated names of parameters for the test, and
    the second argument should be an iterable returning values or tuples of values for
    the case of multiple parameters.

    Beyond this basic usage, the decorator provides some additional functionality that
    pytest does not.

    1. Parametrized tests end up as generated test functions on unittest test classes.
    Since this differs from how pytest works, this decorator takes on the additional
    responsibility of naming these test functions. The default test names consists of
    the test\'s base name followed by each parameter name + value (e.g. "test_bar_x_1_y_foo"),
    but custom names can be defined using `name_fn` or the `subtest` structure (see below).

    2. The decorator specially handles parameter values of type `subtest`, which allows for
    more fine-grained control over both test naming and test execution. In particular, it can
    be used to tag subtests with explicit test names or apply arbitrary decorators (see examples
    below).

    Examples::

        @parametrize("x", range(5))
        def test_foo(self, x):
            ...

        @parametrize("x,y", [(1, \'foo\'), (2, \'bar\'), (3, \'baz\')])
        def test_bar(self, x, y):
            ...

        @parametrize("x,y", [(1, \'foo\'), (2, \'bar\'), (3, \'baz\')],
                     name_fn=lambda x, y: \'{}_{}\'.format(x, y))
        def test_bar_custom_names(self, x, y):
            ...

        @parametrize("x, y", [subtest((1, 2), name=\'double\'),
                              subtest((1, 3), name=\'triple\', decorators=[unittest.expectedFailure]),
                              subtest((1, 4), name=\'quadruple\')])
        def test_baz(self, x, y):
            ...

    Args:
        arg_str (str): String of arg names separate by commas (e.g. "x,y").
        arg_values (iterable): Iterable of arg values (e.g. range(10)) or
            tuples of arg values (e.g. [(1, 2), (3, 4)]).
        name_fn (Callable): Optional function that takes in parameters and returns subtest name.
    '''
    arg_names: Incomplete
    arg_values: Incomplete
    name_fn: Incomplete
    def __init__(self, arg_str, arg_values, name_fn: Incomplete | None = None) -> None: ...

class ProfilingMode(Enum):
    LEGACY: int
    SIMPLE: int
    PROFILING: int

def cppProfilingFlagsToProfilingMode(): ...
def enable_profiling_mode_for_profiling_tests() -> Generator[None, None, None]: ...
def enable_profiling_mode() -> Generator[None, None, None]: ...
def num_profiled_runs(num_runs) -> Generator[None, None, None]: ...

func_call: Incomplete
meth_call: Incomplete

def prof_callable(callable, *args, **kwargs): ...
def prof_func_call(*args, **kwargs): ...
def prof_meth_call(*args, **kwargs): ...

is_running_via_run_test: Incomplete
parser: Incomplete

def run_unittest_help(argv) -> None: ...

help_thread: Incomplete
args: Incomplete
remaining: Incomplete
GRAPH_EXECUTOR: Incomplete
RERUN_DISABLED_TESTS: Incomplete
MAX_NUM_RETRIES: Incomplete
SLOW_TESTS_FILE: Incomplete
DISABLED_TESTS_FILE: Incomplete
LOG_SUFFIX: Incomplete
RUN_PARALLEL: Incomplete
TEST_BAILOUTS: Incomplete
USE_PYTEST: Incomplete
TEST_DISCOVER: Incomplete
TEST_IN_SUBPROCESS: Incomplete
TEST_SAVE_XML: Incomplete
REPEAT_COUNT: Incomplete
SEED: Incomplete
UNITTEST_ARGS: Incomplete
CI_TEST_PREFIX: Incomplete
CI_PT_ROOT: Incomplete
CI_FUNCTORCH_ROOT: Incomplete

def wait_for_process(p): ...
def shell(command, cwd: Incomplete | None = None, env: Incomplete | None = None, stdout: Incomplete | None = None, stderr: Incomplete | None = None): ...
def discover_test_cases_recursively(suite_or_case): ...
def get_test_names(test_cases): ...
def chunk_list(lst, nchunks): ...
def sanitize_test_filename(filename): ...
def lint_test_case_extension(suite): ...
def get_report_path(argv=..., pytest: bool = False): ...
def sanitize_pytest_xml(xml_file: str): ...
def run_tests(argv=...) -> None: ...

IS_LINUX: Incomplete
IS_WINDOWS: Incomplete
IS_MACOS: Incomplete
IS_PPC: Incomplete
IS_X86: Incomplete
IS_ARM64: Incomplete

def is_avx512_vnni_supported(): ...

IS_AVX512_VNNI_SUPPORTED: Incomplete

def TemporaryFileName(*args, **kwargs) -> Generator[Incomplete, None, None]: ...
def TemporaryDirectoryName(suffix: Incomplete | None = None) -> Generator[Incomplete, None, None]: ...

IS_FILESYSTEM_UTF8_ENCODING: Incomplete
TEST_NUMPY: Incomplete
TEST_FAIRSEQ: Incomplete
TEST_SCIPY: Incomplete
TEST_MKL: Incomplete
TEST_CUDA: Incomplete
TEST_NUMBA: Incomplete
TEST_DILL: Incomplete
TEST_LIBROSA: Incomplete
TEST_OPT_EINSUM: Incomplete
BUILD_WITH_CAFFE2: Incomplete
NO_MULTIPROCESSING_SPAWN: Incomplete
TEST_WITH_ASAN: Incomplete
TEST_WITH_DEV_DBG_ASAN: Incomplete
TEST_WITH_TSAN: Incomplete
TEST_WITH_UBSAN: Incomplete
TEST_WITH_ROCM: Incomplete
TEST_WITH_SLOW: Incomplete
TEST_SKIP_FAST: Incomplete
TEST_WITH_CROSSREF: Incomplete
num_procs: Incomplete

def skipIfCrossRef(fn): ...

class CrossRefMode(torch.overrides.TorchFunctionMode):
    def __torch_function__(self, func, types, args=(), kwargs: Incomplete | None = None): ...

TEST_WITH_TORCHINDUCTOR: Incomplete
TEST_WITH_TORCHDYNAMO: Incomplete

def skipIfTorchDynamo(msg: str = "test doesn't currently work with dynamo"): ...
def skipIfTorchInductor(msg: str = "test doesn't currently work with torchinductor"): ...

TEST_CUDA_MEM_LEAK_CHECK: Incomplete
IS_TBB: Incomplete
numpy_to_torch_dtype_dict: Incomplete

def numpy_to_torch_dtype(np_dtype): ...
def has_corresponding_torch_dtype(np_dtype): ...

torch_to_numpy_dtype_dict: Incomplete

def skipIfRocm(fn): ...
def skipIfMps(fn): ...
def skipIfRocmVersionLessThan(version: Incomplete | None = None): ...
def xfailIfPython311(fn): ...
def skipIfNotMiopenSuggestNHWC(fn): ...

class DeterministicGuard:
    deterministic: Incomplete
    warn_only: Incomplete
    def __init__(self, deterministic, *, warn_only: bool = False) -> None: ...
    deterministic_restore: Incomplete
    warn_only_restore: Incomplete
    def __enter__(self) -> None: ...
    def __exit__(self, exception_type: type[BaseException] | None, exception_value: BaseException | None, traceback: types.TracebackType | None) -> None: ...

class AlwaysWarnTypedStorageRemoval:
    always_warn: Incomplete
    def __init__(self, always_warn) -> None: ...
    always_warn_restore: Incomplete
    def __enter__(self) -> None: ...
    def __exit__(self, exception_type: type[BaseException] | None, exception_value: BaseException | None, traceback: types.TracebackType | None) -> None: ...

class CudaSyncGuard:
    mode: Incomplete
    def __init__(self, sync_debug_mode) -> None: ...
    debug_mode_restore: Incomplete
    def __enter__(self) -> None: ...
    def __exit__(self, exception_type: type[BaseException] | None, exception_value: BaseException | None, traceback: types.TracebackType | None) -> None: ...

def wrapDeterministicFlagAPITest(fn): ...
def skipIfCompiledWithoutNumpy(fn): ...
def skipIfNoXNNPACK(fn): ...
def skipIfNoLapack(fn): ...
def skipIfNotRegistered(op_name, message):
    """Wraps the decorator to hide the import of the `core`.

    Args:
        op_name: Check if this op is registered in `core._REGISTERED_OPERATORS`.
        message: message to fail with.

    Usage:
        @skipIfNotRegistered('MyOp', 'MyOp is not linked!')
            This will check if 'MyOp' is in the caffe2.python.core
    """

skipIfCaffe2: Incomplete
skipIfNoCaffe2: Incomplete

def skipIfNoSciPy(fn): ...
def skipIfTBB(message: str = 'This test makes TBB sad'): ...
def slowTest(fn): ...
def slowAwareTest(fn): ...
def skipCUDAMemoryLeakCheckIf(condition): ...
def skipCUDANonDefaultStreamIf(condition): ...
def suppress_warnings(fn): ...
def to_gpu(obj, type_map: Incomplete | None = None): ...
def get_function_arglist(func): ...
def set_rng_seed(seed) -> None: ...
def disable_functorch() -> Generator[None, None, None]: ...
def freeze_rng_state() -> Generator[None, None, None]: ...
def set_default_dtype(dtype) -> Generator[None, None, None]: ...
def iter_indices(tensor): ...
def is_iterable(obj): ...
def is_iterable_of_tensors(iterable, include_empty: bool = False):
    """ Returns True if iterable is an iterable of tensors and False o.w.

        If the iterable is empty, the return value is :attr:`include_empty`
    """

class CudaNonDefaultStream:
    beforeStreams: Incomplete
    def __enter__(self) -> None: ...
    def __exit__(self, exec_type: type[BaseException] | None, exec_value: BaseException | None, traceback: types.TracebackType | None) -> None: ...

class CudaMemoryLeakCheck:
    name: Incomplete
    testcase: Incomplete
    def __init__(self, testcase, name: Incomplete | None = None) -> None: ...
    caching_allocator_befores: Incomplete
    driver_befores: Incomplete
    def __enter__(self) -> None: ...
    def __exit__(self, exec_type: type[BaseException] | None, exec_value: BaseException | None, traceback: types.TracebackType | None) -> None: ...

def skip_exception_type(exc_type) -> Generator[None, None, None]: ...
def settings(*args, **kwargs): ...
def remove_device_and_dtype_suffixes(test_name: str) -> str: ...
def check_if_enable(test: unittest.TestCase): ...

class RelaxedBooleanPair(BooleanPair):
    """Pair for boolean-like inputs.

    In contrast to the builtin :class:`BooleanPair`, this class also supports one input being a number or a single
    element tensor-like.
    """

class RelaxedNumberPair(NumberPair):
    """Pair for number-like inputs.

    In contrast to the builtin :class:`NumberPair`, this class also supports one input being a single element
    tensor-like or a :class:`enum.Enum`. (D)Type checks are disabled, meaning comparing 1 to 1.0 succeeds even when
    ``check_dtype=True`` is passed.

    In addition, this class uses looser default tolerances for :class:`float` and :class:`complex` inputs. Also
    supports overriding the absolute and relative tolerance through the ``@precisionOverride`` and
    ``@toleranceOverride`` decorators.
    """
    rtol: Incomplete
    atol: Incomplete
    def __init__(self, actual, expected, *, rtol_override: float = 0.0, atol_override: float = 0.0, check_dtype: Incomplete | None = None, **other_parameters) -> None: ...

class TensorOrArrayPair(TensorLikePair):
    """Pair for tensor-like inputs.

    On the one hand this class is stricter than the builtin :class:`TensorLikePair` since it only allows instances of
    :class:`torch.Tensor` and :class:`numpy.ndarray` rather than allowing any tensor-like than can be converted into a
    tensor. On the other hand this class is looser since it converts all inputs into tensors with no regard of their
    relationship, e.g. comparing a :class:`torch.Tensor` to :class:`numpy.ndarray` is fine.

    In addition, this class supports overriding the absolute and relative tolerance through the ``@precisionOverride``
    and ``@toleranceOverride`` decorators.
    """
    rtol: Incomplete
    atol: Incomplete
    def __init__(self, actual, expected, *, rtol_override: float = 0.0, atol_override: float = 0.0, **other_parameters) -> None: ...

class TypedStoragePair(TensorLikePair):
    """Pair for :class:`torch.storage.TypedStorage` inputs."""
    rtol: Incomplete
    atol: Incomplete
    def __init__(self, actual, expected, *, rtol_override: float = 0.0, atol_override: float = 0.0, **other_parameters) -> None: ...

class UnittestPair(Pair):
    '''Fallback ABC pair that handles non-numeric inputs.

    To avoid recreating the mismatch messages of :meth:`unittest.TestCase.assertEqual`, this pair simply wraps it in
    order to use it with the :class:`Pair` "framework" from :func:`are_equal`.

    Define the :attr:`UnittestPair.CLS` in a subclass to indicate which class(es) of the inputs the pair should support.
    '''
    CLS: Type | Tuple[Type, ...]
    TYPE_NAME: str | None
    def __init__(self, actual, expected, **other_parameters) -> None: ...
    def compare(self): ...

class StringPair(UnittestPair):
    CLS: Incomplete
    TYPE_NAME: str

class SetPair(UnittestPair):
    CLS = set

class TypePair(UnittestPair):
    CLS = type

class ObjectPair(UnittestPair):
    CLS = object

class AssertRaisesContextIgnoreNotImplementedError(unittest.case._AssertRaisesContext):
    def __exit__(self, exc_type: type[BaseException] | None, exc_value: BaseException | None, tb: types.TracebackType | None): ...

def set_warn_always_context(new_val: bool): ...

class TestCase(expecttest.TestCase):
    @property
    def precision(self) -> float: ...
    @precision.setter
    def precision(self, prec: float) -> None: ...
    @property
    def rel_tol(self) -> float: ...
    @rel_tol.setter
    def rel_tol(self, prec: float) -> None: ...
    def __init__(self, method_name: str = 'runTest') -> None: ...
    def assertLeaksNoCudaTensors(self, name: Incomplete | None = None): ...
    def enforceNonDefaultStream(self): ...
    def wrap_with_cuda_policy(self, method_name, policy) -> None: ...
    def wrap_with_policy(self, method_name, policy) -> None: ...
    def wrap_method_with_policy(self, method, policy): ...
    def wrap_with_cuda_memory_check(self, method): ...
    def run(self, result: Incomplete | None = None) -> None: ...
    def setUp(self) -> None: ...
    def tearDown(self) -> None: ...
    def genSparseCompressedTensor(self, size, nnz, *, layout, device, dtype, index_dtype, blocksize=(), dense_dims: int = 0): ...
    def genSparseCSRTensor(self, size, nnz, *, device, dtype, index_dtype, dense_dims: int = 0): ...
    def genSparseCSCTensor(self, size, nnz, *, device, dtype, index_dtype, dense_dims: int = 0): ...
    def genSparseBSRTensor(self, size, blocksize, nnz, *, device, dtype, index_dtype, dense_dims: int = 0): ...
    def genSparseBSCTensor(self, size, blocksize, nnz, *, device, dtype, index_dtype, dense_dims: int = 0): ...
    def genSparseTensor(self, size, sparse_dim, nnz, is_uncoalesced, device, dtype): ...
    def generate_simple_inputs(self, layout, device: Incomplete | None = None, dtype: Incomplete | None = None, index_dtype: Incomplete | None = None, enable_batch: bool = True, enable_hybrid: bool = True, enable_zero_sized: bool = True, enable_non_contiguous_indices: bool = True, enable_non_contiguous_values: bool = True, enable_batch_variable_nse: bool = False, output_tensor: bool = True, patterns: Incomplete | None = None) -> Generator[Incomplete, None, Incomplete]:
        """Generator of simple inputs for tensor constructors of the given layout.

        The generated tensor inputs have the following properties:

        - tensor shapes are minimal but not trivial
        - tensor values are sorted sequences for COO and CSR formats, e.g. [1, 2, 3, 4]
        - the generated tensors represent the same mathematical tensor for all layouts
        - the generated tensors include regular, zero-sized, and optionally, batched or/and hybrid tensors.
        - the generated tensors include contiguous or non-contiguous tensors both in indices and values

        If output_tensor is True, yield tensors with the given
        layout. Otherwise, yield inputs to the corresponding tensor
        constructors:

          - sparse compressed input is defined as
            (compressed_indices, plain_indices, values), dict(size=expected_size_from_shape_inference, device=device, dtype=dtype)

          - sparse COO input is defined as
            (indices, values), dict(size=expected_size_from_shape_inference, device=device, dtype=dtype)

          - strided input is defined as
            (values,), dict(device=device, dtype=dtype)
        """
    def safeToDense(self, t): ...
    def compare_with_reference(self, torch_fn, ref_fn, sample_input, **kwargs) -> None: ...
    def compare_with_numpy(self, torch_fn, np_fn, tensor_like, device: Incomplete | None = None, dtype: Incomplete | None = None, **kwargs) -> None: ...
    def assertEqualIgnoreType(self, *args, **kwargs) -> None: ...
    def assertEqualBroadcasting(self, x, y, *args, **kwargs) -> None:
        """Tests if tensor x equals to y, if y to be broadcast to x.shape.
        """
    def assertEqual(self, x, y, msg: str | Callable[[str], str] | None = None, *, atol: float | None = None, rtol: float | None = None, equal_nan: bool = True, exact_dtype: bool = True, exact_device: bool = False, exact_layout: bool = False, exact_stride: bool = False, exact_is_coalesced: bool = False): ...
    def assertNotEqual(self, x, y, msg: str | None = None, *, atol: float | None = None, rtol: float | None = None, **kwargs) -> None: ...
    def assertEqualTypeString(self, x, y) -> None: ...
    def assertObjectIn(self, obj: Any, iterable: Iterable[Any]) -> None: ...
    def assertRaises(self, expected_exception, *args, **kwargs): ...
    def assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs): ...
    def assertNoUnraisable(self, callable, *args, **kwargs) -> None: ...
    def assertExpectedRaises(self, exc_type, callable, *args, **kwargs) -> None: ...
    def assertNotWarn(self, callable, msg: str = '') -> None:
        """
        Test if :attr:`callable` does not raise a warning.
        """
    def assertWarnsOnceRegex(self, category, regex: str = '') -> Generator[None, None, None]:
        """Context manager for code that *must always* warn

        This filters expected warnings from the test and fails if
        the expected warning is not caught. It uses set_warn_always() to force
        TORCH_WARN_ONCE to behave like TORCH_WARN
        """
    def assertExpected(self, s, subname: Incomplete | None = None):
        """
        Test that a string matches the recorded contents of a file
        derived from the name of this test and subname.  This file
        is placed in the 'expect' directory in the same directory
        as the test script. You can automatically update the recorded test
        output using --accept.

        If you call this multiple times in a single function, you must
        give a unique subname each time.
        """
    def assertExpectedStripMangled(self, s, subname: Incomplete | None = None) -> None: ...
    def assertGreaterAlmostEqual(self, first, second, places: Incomplete | None = None, msg: Incomplete | None = None, delta: Incomplete | None = None) -> None:
        """Assert that ``first`` is greater than or almost equal to ``second``.

        The equality of ``first`` and ``second`` is determined in a similar way to
        the ``assertAlmostEqual`` function of the standard library.
        """
    def assertAtenOp(self, onnx_model, operator, overload_name: str = '') -> None: ...
    def check_nondeterministic_alert(self, fn, caller_name, should_alert: bool = True) -> None:
        """Checks that an operation produces a nondeterministic alert when
        expected while `torch.use_deterministic_algorithms(True)` is set.

        Args:
          fn (callable): Function to check for a nondeterministic alert

          caller_name (str): Name of the operation that produces the
              nondeterministic alert. This name is expected to appear at the
              beginning of the error/warning message.

          should_alert (bool, optional): If True, then the check will only pass
              if calling `fn` produces a nondeterministic error/warning with the
              expected message. If False, then the check will only pass if
              calling `fn` does not produce an error. Default: `True`.
        """
    @staticmethod
    def run_process_no_exception(code, env: Incomplete | None = None): ...
    @staticmethod
    def runWithPytorchAPIUsageStderr(code): ...

def download_file(url, binary: bool = True): ...
def find_free_port():
    """
    Finds an available port and returns that port number.

    NOTE: If this function is being used to allocate a port to Store (or
    indirectly via init_process_group or init_rpc), it should be used
    in conjuction with the `retry_on_connect_failures` decorator as there is a potential
    race condition where the allocated port may become unavailable before it can be used
    """

ADDRESS_IN_USE: str
CONNECT_TIMEOUT: str

def retry_on_connect_failures(func: Incomplete | None = None, connect_errors=...):
    """Reruns a test if the test returns a RuntimeError and the exception
    contains one of the strings in connect_errors."""
def retry(ExceptionToCheck, tries: int = 3, delay: int = 3, skip_after_retries: bool = False): ...
def random_square_matrix_of_rank(l, rank, dtype=..., device: str = 'cpu'): ...
def random_well_conditioned_matrix(*shape, dtype, device, mean: float = 1.0, sigma: float = 0.001):
    """
    Returns a random rectangular matrix (batch of matrices)
    with singular values sampled from a Gaussian with
    mean `mean` and standard deviation `sigma`.
    The smaller the `sigma`, the better conditioned
    the output matrix is.
    """
def noncontiguous_like(t): ...
def random_symmetric_matrix(l, *batches, **kwargs): ...
def make_symmetric_matrices(*shape, device, dtype): ...
def random_hermitian_matrix(l, *batches, **kwargs): ...
def random_symmetric_psd_matrix(l, *batches, **kwargs):
    '''
    Returns a batch of random symmetric positive-semi-definite matrices.
    The shape of the result is batch_dims + (matrix_size, matrix_size)
    The following example creates a tensor of size 2 x 4 x 3 x 3
    >>> # xdoctest: +SKIP("undefined variables")
    >>> matrices = random_symmetric_psd_matrix(3, 2, 4, dtype=dtype, device=device)
    '''
def random_hermitian_psd_matrix(matrix_size, *batch_dims, dtype=..., device: str = 'cpu'):
    '''
    Returns a batch of random Hermitian positive-semi-definite matrices.
    The shape of the result is batch_dims + (matrix_size, matrix_size)
    The following example creates a tensor of size 2 x 4 x 3 x 3
    >>> # xdoctest: +SKIP("undefined variables")
    >>> matrices = random_hermitian_psd_matrix(3, 2, 4, dtype=dtype, device=device)
    '''
def random_symmetric_pd_matrix(matrix_size, *batch_dims, **kwargs): ...
def make_symmetric_pd_matrices(*shape, device, dtype): ...
def random_hermitian_pd_matrix(matrix_size, *batch_dims, dtype, device):
    '''
    Returns a batch of random Hermitian positive-definite matrices.
    The shape of the result is batch_dims + (matrix_size, matrix_size)
    The following example creates a tensor of size 2 x 4 x 3 x 3
    >>> # xdoctest: +SKIP("undefined variables")
    >>> matrices = random_hermitian_pd_matrix(3, 2, 4, dtype=dtype, device=device)
    '''
def make_fullrank_matrices_with_distinct_singular_values(*shape, device, dtype, requires_grad: bool = False): ...
def random_matrix(rows, columns, *batch_dims, **kwargs):
    """Return rectangular matrix or batches of rectangular matrices.

    Parameters:
      dtype - the data type
      device - the device kind
      singular - when True, the output will be singular
    """
def random_lowrank_matrix(rank, rows, columns, *batch_dims, **kwargs):
    """Return rectangular matrix or batches of rectangular matrices with
    given rank.
    """
def random_sparse_matrix(rows, columns, density: float = 0.01, **kwargs):
    """Return rectangular random sparse matrix within given density.

    The density of the result approaches to given density as the size
    of the matrix is increased and a relatively small value of density
    is specified but higher than min(rows, columns)/(rows * columns)
    for non-singular matrices.
    """
def random_sparse_pd_matrix(matrix_size, density: float = 0.01, **kwargs):
    """Return random sparse positive-definite matrix with given density.

    The eigenvalues of the matrix are defined as::
      arange(1, matrix_size+1)/matrix_size

    Algorithm:
      A = diag(arange(1, matrix_size+1)/matrix_size)
      while <A density is smaller than required>:
          <choose random i, j in range(matrix_size), theta in [0, 2*pi]>
          R = <rotation matrix (i,j,theta)>
          A = R^T A R
    """
def do_test_dtypes(self, dtypes, layout, device) -> None: ...
def do_test_empty_full(self, dtypes, layout, device): ...

running_script_path: Incomplete

def set_running_script_path() -> None: ...
def check_test_defined_in_running_script(test_case) -> None: ...
def load_tests(loader, tests, pattern): ...

class BytesIOContext(io.BytesIO):
    def __enter__(self): ...
    def __exit__(self, *args) -> None: ...

GRADCHECK_NONDET_TOL: float

def is_slow_gradcheck_env() -> bool: ...

skipIfSlowGradcheckEnv: Incomplete

def gradcheck(fn, inputs, **kwargs): ...
def gradgradcheck(fn, inputs, grad_outputs: Incomplete | None = None, **kwargs): ...
def set_cwd(path: str) -> Iterator[None]: ...

dtype2prec_DONTUSE: Incomplete

def coalescedonoff(f): ...
def is_coalesced_indices(s): ...
def disable_gc() -> Generator[None, None, None]: ...
def find_library_location(lib_name: str) -> Path: ...
def sandcastle_skip(reason):
    '''
    Similar to unittest.skip, however in the sandcastle environment it just
    "passes" the test instead to avoid creating tasks complaining about tests
    skipping continuously.
    '''
def mock_wrapper(method):
    """
    Returns a function that calls the real implementation of a method
    in addition to passing args to a mock object.
    """
def get_tensors_from(args, kwargs):
    """ Returns a set of all Tensor objects in the given args and kwargs. """
def bytes_to_scalar(byte_list: List[int], dtype: torch.dtype, device: torch.device): ...
def copy_func(f):
    """Based on http://stackoverflow.com/a/6528148/190597 (Glenn Maynard)"""
def xfail_inherited_tests(tests):
    """
    Given a list of test names which are defined by a superclass of the
    class this decorates, mark them as expected failure.  This is useful
    if you are doing poor man's parameterized tests by subclassing a generic
    test class.
    """
def sandcastle_skip_if(condition, reason):
    '''
    Similar to unittest.skipIf, however in the sandcastle environment it just
    "passes" the test instead to avoid creating tasks complaining about tests
    skipping continuously.
    '''
def dtype_name(dtype):
    """ Returns the pretty name of the dtype (e.g. torch.int64 -> int64). """

dtype_abbrs: Incomplete

def set_single_threaded_if_parallel_tbb(fn):
    """Set test to be single threaded for parallel tbb.

    See https://github.com/pytorch/pytorch/issues/64571#issuecomment-914691883
    """
def get_cycles_per_ms() -> float:
    """Measure and return approximate number of cycles per millisecond for torch.cuda._sleep
    """
T = TypeVar('T')

def first_sample(self, samples: Iterable[T]) -> T:
    """
    Returns the first sample from an iterable of samples, like those returned by OpInfo.
    The test will be skipped if no samples are available.
    """
def clone_input_helper(input): ...
def custom_op(opname, symbolic_fn, opset_version) -> Generator[None, None, None]:
    """Context manager/decorator to test ONNX export with custom oeprator"""
def outs_and_grads(fn, graph_inps, inps): ...
def compare_equal_outs_and_grads(test, m1, m2, inps) -> None: ...

class TestGradients(TestCase):
    exact_dtype: bool
