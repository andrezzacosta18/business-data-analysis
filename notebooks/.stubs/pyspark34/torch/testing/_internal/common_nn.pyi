import abc
from _typeshed import Incomplete
from torch.autograd import Variable as Variable
from torch.testing._internal.common_cuda import TEST_CUDA as TEST_CUDA
from torch.testing._internal.common_utils import TEST_WITH_ROCM as TEST_WITH_ROCM, TestCase as TestCase, freeze_rng_state as freeze_rng_state, gradcheck as gradcheck, gradgradcheck as gradgradcheck, is_iterable as is_iterable, to_gpu as to_gpu
from torch.types import _TensorOrTensors
from typing import Callable, Dict

TemporaryFile: Incomplete
PRECISION: float

def get_reduction(m): ...
def get_weight(m): ...

module_tests: Incomplete

def wrap_functional(fn, **kwargs): ...
def poissonnllloss_no_reduce_test(): ...
def bceloss_no_reduce_test(): ...
def bceloss_no_reduce_scalar_test(): ...
def bceloss_weights_no_reduce_test(): ...
def bceloss_weights_no_reduce_scalar_test(): ...
def bce_with_logistic_legacy_enum_test(): ...
def bce_with_logistic_no_reduce_test(): ...
def bce_with_logistic_no_reduce_scalar_test(): ...
def kldivloss_with_target_no_reduce_test(): ...
def kldivloss_no_reduce_test(): ...
def kldivloss_no_reduce_scalar_test(): ...
def kldivloss_with_log_target_no_reduce_test(): ...
def kldivloss_no_reduce_log_target_test(): ...
def kldivloss_no_reduce_scalar_log_target_test(): ...
def l1loss_no_reduce_test(): ...
def l1loss_no_reduce_complex_test(): ...
def l1loss_no_reduce_scalar_test(): ...
def mseloss_no_reduce_test(): ...
def mseloss_no_reduce_scalar_test(): ...
def nllloss_no_reduce_test(): ...
def nllloss_no_reduce_ignore_index_test(): ...
def nllloss_no_reduce_weights_test(): ...
def nllloss_no_reduce_weights_ignore_index_test(): ...
def nllloss_no_reduce_weights_ignore_index_neg_test(): ...
def nllloss2d_no_reduce_test(): ...
def nllloss2d_no_reduce_ignore_index_test(): ...
def nllloss2d_no_reduce_weights_test(): ...
def nlllossNd_no_reduce_test(): ...
def nlllossNd_no_reduce_ignore_index_test(): ...
def nlllossNd_no_reduce_weights_test(): ...
def smoothl1loss_no_reduce_test(): ...
def smoothl1loss_no_reduce_scalar_test(): ...
def smoothl1loss_beta_test(): ...
def smoothl1loss_zero_beta_test(): ...
def huberloss_delta_test(): ...
def multilabelmarginloss_0d_no_reduce_test(): ...
def multilabelmarginloss_1d_no_reduce_test(): ...
def multilabelmarginloss_index_neg_test(): ...
def multilabelmarginloss_no_reduce_test(): ...
def hingeembeddingloss_no_reduce_test(): ...
def hingeembeddingloss_margin_no_reduce_test(): ...
def softmarginloss_no_reduce_test(): ...
def multilabelsoftmarginloss_no_reduce_test(): ...
def multilabelsoftmarginloss_weights_no_reduce_test(): ...
def multimarginloss_no_reduce_test(): ...
def multimarginloss_1d_no_reduce_test(): ...
def multimarginloss_1d_input_0d_target_no_reduce_test(): ...
def multimarginloss_p_no_reduce_test(): ...
def multimarginloss_margin_no_reduce_test(): ...
def multimarginloss_weights_no_reduce_test(): ...
def fractional_max_pool2d_test(test_case, return_indices: bool = False): ...
def fractional_max_pool2d_no_batch_dim_test(test_case, use_random_samples): ...
def fractional_max_pool3d_test(test_case, return_indices: bool = False): ...
def fractional_max_pool3d_no_batch_dim_test(test_case, use_random_samples): ...
def single_batch_reference_fn(input, parameters, module):
    """Reference function for modules supporting no batch dimensions.

    The module is passed the input and target in batched form with a single item.
    The output is squeezed to compare with the no-batch input.
    """

new_module_tests: Incomplete
padding: Incomplete
cpp_padding: Incomplete
input_size: Incomplete
output_size: Incomplete
non_linear_activations_no_batch: Incomplete
non_linear_activations_extra_info: Dict[str, dict]
activation_test_info: Incomplete
extra_info: Incomplete

def kldivloss_reference(input, target, reduction: str = 'mean'): ...
def kldivloss_log_target_reference(input, target, reduction: str = 'mean'): ...
def nlllossNd_reference(input, target, weight: Incomplete | None = None, ignore_index: int = -100, reduction: str = 'mean'): ...
def cross_entropy_loss_prob_target_reference(input, target, weight: Incomplete | None = None, reduction: str = 'mean', label_smoothing: float = 0.0): ...
def cross_entropy_loss_indices_target_reference(input, target, weight: Incomplete | None = None, ignore_index: int = -100, reduction: str = 'mean', label_smoothing: float = 0.0): ...
def cross_entropy_loss_reference(input, target, weight: Incomplete | None = None, ignore_index: int = -100, reduction: str = 'mean', label_smoothing: float = 0.0): ...
def nllloss_reference(input, target, weight: Incomplete | None = None, ignore_index: int = -100, reduction: str = 'mean'): ...
def smoothl1loss_reference(input, target, reduction: str = 'mean', beta: float = 1.0): ...
def huberloss_reference(input, target, reduction: str = 'mean', delta: float = 1.0): ...
def multilabelmarginloss_reference(input, target, reduction: str = 'mean'): ...
def hingeembeddingloss_reference(input, target, margin: float = 1.0, reduction: str = 'mean'): ...
def softmarginloss_reference(input, target, reduction: str = 'mean'): ...
def multimarginloss_reference(input, target, p: int = 1, margin: int = 1, weight: Incomplete | None = None, reduction: str = 'mean'): ...
def cosineembeddingloss_reference(input1, input2, target, margin: int = 0, reduction: str = 'mean'): ...
def tripletmarginloss_reference(anchor, positive, negative, margin: float = 1.0, p: int = 2, eps: float = 1e-06, swap: bool = False, reduction: str = 'mean'): ...
def marginrankingloss_reference(input1, input2, target, margin: int = 0, reduction: str = 'mean'): ...
def ctcloss_reference(log_probs, targets, input_lengths, target_lengths, blank: int = 0, reduction: str = 'mean'): ...
def padding1d_circular(input, pad):
    """ input:
            [[[0., 1., 2.],
              [3., 4., 5.]]]
          pad: (1, 2)
          output:
            [[[2., 0., 1., 2., 0., 1.],
              [5., 3., 4., 5., 3., 4.]]]
    """
def padding2d_circular(input, pad):
    """input:
             [[[[0., 1., 2],
                [3., 4., 5.]]]]
            pad: (1, 2, 2, 1)
    output:
        [[[[2., 0., 1., 2., 0., 1.],
           [5., 3., 4., 5., 3., 4.],
           [2., 0., 1., 2., 0., 1.],
           [5., 3., 4., 5., 3., 4.],
           [2., 0., 1., 2., 0., 1.]]]]
    """
def padding3d_circular(input, pad):
    """input:
            [[[[[ 0.,  1.,  2.],
                [ 3.,  4.,  5.]],
               [[ 6.,  7.,  8.],
                [ 9., 10., 11.]]]]]
        pad: (1, 2, 2, 1, 1, 2)
        output: [[[[[ 8.,  6.,  7.,  8.,  6.,  7.],
               [11.,  9., 10., 11.,  9., 10.],
               [ 8.,  6.,  7.,  8.,  6.,  7.],
               [11.,  9., 10., 11.,  9., 10.],
               [ 8.,  6.,  7.,  8.,  6.,  7.]],

              [[ 2.,  0.,  1.,  2.,  0.,  1.],
               [ 5.,  3.,  4.,  5.,  3.,  4.],
               [ 2.,  0.,  1.,  2.,  0.,  1.],
               [ 5.,  3.,  4.,  5.,  3.,  4.],
               [ 2.,  0.,  1.,  2.,  0.,  1.]],

              [[ 8.,  6.,  7.,  8.,  6.,  7.],
               [11.,  9., 10., 11.,  9., 10.],
               [ 8.,  6.,  7.,  8.,  6.,  7.],
               [11.,  9., 10., 11.,  9., 10.],
               [ 8.,  6.,  7.,  8.,  6.,  7.]],

              [[ 2.,  0.,  1.,  2.,  0.,  1.],
               [ 5.,  3.,  4.,  5.,  3.,  4.],
               [ 2.,  0.,  1.,  2.,  0.,  1.],
               [ 5.,  3.,  4.,  5.,  3.,  4.],
               [ 2.,  0.,  1.,  2.,  0.,  1.]],

              [[ 8.,  6.,  7.,  8.,  6.,  7.],
               [11.,  9., 10., 11.,  9., 10.],
               [ 8.,  6.,  7.,  8.,  6.,  7.],
               [11.,  9., 10., 11.,  9., 10.],
               [ 8.,  6.,  7.,  8.,  6.,  7.]]]]]
    """

loss_reference_fns: Dict['str', Callable]
criterion_tests: Incomplete

def single_batch_reference_criterion_fn(*args):
    """Reference function for criterion supporting no batch dimensions.

    The criterion is passed the input and target in batched form with a single item.
    The output is squeezed to compare with the no-batch input.
    """

regression_criterion_no_batch: Incomplete
reductions: Incomplete
regression_test_info: Incomplete
classification_criterion_no_batch: Incomplete
classification_criterion_no_batch_extra_info: Dict[str, dict]
classification_cpp_parity: Incomplete
classification_test_info: Incomplete

class NNTestCase(TestCase, metaclass=abc.ABCMeta):
    def check_jacobian(self, module, input: _TensorOrTensors, jacobian_input: bool = True): ...

class TestBase:
    desc: Incomplete
    fullname: Incomplete
    constructor: Incomplete
    reference_fn: Incomplete
    def __init__(self, constructor, desc: str = '', reference_fn: Incomplete | None = None, fullname: Incomplete | None = None, **kwargs) -> None: ...
    def get_name(self): ...
    @property
    def constructor_args(self): ...
    @property
    def extra_args(self): ...
    def __call__(self, test_case) -> None: ...

class ModuleTest(TestBase, metaclass=abc.ABCMeta):
    jacobian_input: Incomplete
    should_test_cuda: Incomplete
    should_test_pickle: Incomplete
    check_gradgrad: Incomplete
    FIXME_no_cuda_gradgrad_comparison: Incomplete
    precision: Incomplete
    check_forward_only: Incomplete
    def __init__(self, *args, **kwargs) -> None: ...
    def __call__(self, test_case) -> None: ...
    def noncontiguize(self, obj): ...
    def test_noncontig(self, test_case, module, input) -> None: ...
    def test_cuda(self, test_case) -> None: ...

class InputVariableMixin: ...

class NewModuleTest(InputVariableMixin, ModuleTest):
    cudnn: Incomplete
    check_inplace: Incomplete
    check_gradgrad: Incomplete
    skip_double: Incomplete
    skip_half: Incomplete
    with_tf32: Incomplete
    tf32_precision: Incomplete
    test_cpu: Incomplete
    has_sparse_gradients: Incomplete
    check_batched_grad: Incomplete
    gradcheck_fast_mode: Incomplete
    supports_forward_ad: Incomplete
    supports_fwgrad_bwgrad: Incomplete
    def __init__(self, *args, **kwargs) -> None: ...
    @property
    def constructor_args(self): ...

class CriterionTest(InputVariableMixin, TestBase):
    should_test_cuda: Incomplete
    check_forward_only: Incomplete
    check_gradgrad: Incomplete
    check_half: Incomplete
    check_bfloat16: Incomplete
    check_complex: Incomplete
    test_cpu: Incomplete
    with_tf32: Incomplete
    tf32_precision: Incomplete
    check_batched_grad: Incomplete
    def __init__(self, *args, **kwargs) -> None: ...
    def __call__(self, test_case): ...
    def test_cuda(self, test_case, dtype, extra_args: Incomplete | None = None): ...
    @property
    def constructor_args(self): ...
    @property
    def extra_args(self): ...
