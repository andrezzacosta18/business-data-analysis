from _typeshed import Incomplete
from torch.utils.data import Dataset as Dataset, IterableDataset as IterableDataset, default_collate as default_collate
from torch.utils.data.datapipes._typing import _DataPipeMeta, _IterDataPipeMeta
from typing import Any, Callable, Dict, Generic, Iterator, List, TypeVar

T_co = TypeVar('T_co', covariant=True)
T = TypeVar('T')
UNTRACABLE_DATAFRAME_PIPES: Any

class MapDataPipe(Dataset[T_co], metaclass=_DataPipeMeta):
    functions: Dict[str, Callable]
    reduce_ex_hook: Callable | None
    getstate_hook: Callable | None
    str_hook: Callable | None
    repr_hook: Callable | None
    def __getattr__(self, attribute_name: Any): ...
    @classmethod
    def register_function(cls, function_name: Any, function: Any) -> None: ...
    @classmethod
    def register_datapipe_as_function(cls, function_name: Any, cls_to_register: Any): ...
    def __reduce_ex__(self, *args: Any, **kwargs: Any): ...
    @classmethod
    def set_getstate_hook(cls, hook_fn: Any) -> None: ...
    @classmethod
    def set_reduce_ex_hook(cls, hook_fn: Any) -> None: ...
    def batch(self, batch_size: int, drop_last: bool = False, wrapper_class=...) -> MapDataPipe: ...
    def concat(self, *datapipes: MapDataPipe) -> MapDataPipe: ...
    def map(self, fn: Callable = ...) -> MapDataPipe: ...
    def shuffle(self, *, indices: List | None = None) -> IterDataPipe: ...
    def zip(self, *datapipes: MapDataPipe[T_co]) -> MapDataPipe: ...

class IterDataPipe(IterableDataset[T_co], metaclass=_IterDataPipeMeta):
    functions: Dict[str, Callable]
    reduce_ex_hook: Callable | None
    getstate_hook: Callable | None
    str_hook: Callable | None
    repr_hook: Callable | None
    def __getattr__(self, attribute_name: Any): ...
    @classmethod
    def register_function(cls, function_name: Any, function: Any) -> None: ...
    @classmethod
    def register_datapipe_as_function(cls, function_name: Any, cls_to_register: Any, enable_df_api_tracing: bool = ...): ...
    def __reduce_ex__(self, *args: Any, **kwargs: Any): ...
    @classmethod
    def set_getstate_hook(cls, hook_fn: Any) -> None: ...
    @classmethod
    def set_reduce_ex_hook(cls, hook_fn: Any) -> None: ...
    def batch(self, batch_size: int, drop_last: bool = False, wrapper_class=...) -> IterDataPipe: ...
    def collate(self, conversion: Callable[..., Any] | Dict[str | Any, Callable | Any] | None = ..., collate_fn: Callable | None = None) -> IterDataPipe: ...
    def concat(self, *datapipes: IterDataPipe) -> IterDataPipe: ...
    def demux(self, num_instances: int, classifier_fn: Callable[[T_co], int | None], drop_none: bool = False, buffer_size: int = 1000) -> List[IterDataPipe]: ...
    def filter(self, filter_fn: Callable, input_col: Incomplete | None = None) -> IterDataPipe: ...
    def fork(self, num_instances: int, buffer_size: int = 1000) -> List[IterDataPipe]: ...
    def groupby(self, group_key_fn: Callable[[T_co], Any], *, keep_key: bool = False, buffer_size: int = 10000, group_size: int | None = None, guaranteed_group_size: int | None = None, drop_remaining: bool = False) -> IterDataPipe: ...
    def list_files(self, masks: str | List[str] = '', *, recursive: bool = False, abspath: bool = False, non_deterministic: bool = False, length: int = -1) -> IterDataPipe: ...
    def map(self, fn: Callable, input_col: Incomplete | None = None, output_col: Incomplete | None = None) -> IterDataPipe: ...
    def mux(self, *datapipes) -> IterDataPipe: ...
    def open_files(self, mode: str = 'r', encoding: str | None = None, length: int = -1) -> IterDataPipe: ...
    def read_from_stream(self, chunk: Incomplete | None = None) -> IterDataPipe: ...
    def routed_decode(self, *handlers: Callable, key_fn: Callable = ...) -> IterDataPipe: ...
    def sharding_filter(self, sharding_group_filter: Incomplete | None = None) -> IterDataPipe: ...
    def shuffle(self, *, buffer_size: int = 10000, unbatch_level: int = 0) -> IterDataPipe: ...
    def unbatch(self, unbatch_level: int = 1) -> IterDataPipe: ...
    def zip(self, *datapipes: IterDataPipe) -> IterDataPipe: ...

class DFIterDataPipe(IterDataPipe): ...

class _DataPipeSerializationWrapper:
    def __init__(self, datapipe) -> None: ...
    def __len__(self) -> int: ...

class _IterDataPipeSerializationWrapper(_DataPipeSerializationWrapper, IterDataPipe):
    def __iter__(self): ...

class _MapDataPipeSerializationWrapper(_DataPipeSerializationWrapper, MapDataPipe):
    def __getitem__(self, idx) -> None: ...

class DataChunk(list, Generic[T]):
    items: Incomplete
    def __init__(self, items) -> None: ...
    def as_str(self, indent: str = ''): ...
    def __iter__(self) -> Iterator[T]: ...
    def raw_iterator(self) -> T: ...
