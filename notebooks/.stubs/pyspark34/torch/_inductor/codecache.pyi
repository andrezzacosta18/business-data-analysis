import dataclasses
import torch
from . import config as config, cuda_properties as cuda_properties, exc as exc
from .utils import developer_warning as developer_warning
from _typeshed import Incomplete
from torch.hub import tqdm as tqdm
from torch.utils import cpp_extension as cpp_extension
from typing import Any, Callable, Dict

LOCK_TIMEOUT: int
log: Incomplete

def cache_dir(): ...

class DiskCache:
    unique_name: Incomplete
    def __init__(self, unique_name) -> None: ...
    def lookup(self, key: Any, generate: Callable[[], Any]):
        """
        Check if we have already generated key, if not call generate()
        to populate the cache.
        """

def get_lock_dir(): ...
def code_hash(code): ...
def get_code_path(source_code, ext, extra): ...
def write(source_code, ext, extra: str = ''): ...
def write_atomic(path: str, source_code: str): ...
def cpp_compiler(): ...
def cpp_compiler_search(search): ...
def install_gcc_via_conda():
    """On older systems, this is a quick way to get a modern compiler"""
def is_gcc(): ...

class VecISA:
    def bit_width(self): ...
    def nelements(self, dtype: torch.dtype = ...): ...
    def build_macro(self): ...
    def build_arch_flags(self): ...
    def __hash__(self) -> int: ...
    def __bool__(self) -> bool: ...

@dataclasses.dataclass
class VecAVX512(VecISA):
    __hash__: Callable[[VecISA], Any] = ...
    def __init__(self, __hash__) -> None: ...

@dataclasses.dataclass
class VecAVX2(VecISA):
    __hash__: Callable[[VecISA], Any] = ...
    def __init__(self, __hash__) -> None: ...

class InvalidVecISA(VecISA):
    def __bool__(self) -> bool: ...
    __hash__: Callable[[VecISA], Any]

invalid_vec_isa: Incomplete
supported_vec_isa_list: Incomplete

def valid_vec_isa_list(): ...
def pick_vec_isa(): ...
def get_shared(shared: bool = True): ...
def get_warning_all_flag(warning_all: bool = True): ...
def cpp_flags(): ...
def optimization_flags(): ...
def use_custom_generated_macros(): ...
def get_include_and_linking_paths(include_pytorch: bool = False, vec_isa: VecISA = ...): ...
def cpp_compile_command(input, output, warning_all: bool = True, shared: bool = True, include_pytorch: bool = False, vec_isa: VecISA = ...): ...

class CppCodeCache:
    cache: Incomplete
    clear: Incomplete
    @classmethod
    def load(cls, source_code): ...

class PyCodeCache:
    cache: Incomplete
    clear: Incomplete
    @classmethod
    def load(cls, source_code): ...

class TritonCodeCache:
    @staticmethod
    def get_name(mod): ...
    @classmethod
    def load(cls, source_code): ...

class TritonFuture:
    source_code: Incomplete
    future: Incomplete
    def __init__(self, source_code, future) -> None: ...
    def result(self): ...

class AsyncCompile:
    def __init__(self) -> None: ...
    @staticmethod
    def pool(): ...
    @staticmethod
    def process_pool(): ...
    @classmethod
    def warm_pool(cls) -> None: ...
    @classmethod
    def submit(cls, task): ...
    @classmethod
    def map(cls, fn, seq): ...
    def triton(self, source_code): ...
    def cpp(self, source_code): ...
    def wait(self, scope: Dict[str, Any]): ...
