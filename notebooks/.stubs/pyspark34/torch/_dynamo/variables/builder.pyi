import dataclasses
import torch
from .. import config as config, mutation_guard as mutation_guard, replay_record as replay_record, skipfiles as skipfiles
from ..allowed_functions import is_allowed as is_allowed, is_builtin_callable as is_builtin_callable, is_numpy as is_numpy
from ..exc import unimplemented as unimplemented
from ..guards import GuardBuilder as GuardBuilder
from ..side_effects import SideEffects as SideEffects
from ..source import AttrSource as AttrSource, ConstantSource as ConstantSource, GetItemSource as GetItemSource, GlobalSource as GlobalSource, GlobalWeakRefSource as GlobalWeakRefSource, LocalInputSource as LocalInputSource, LocalSource as LocalSource, RandomValueSource as RandomValueSource, Source as Source, TupleIteratorGetItemSource as TupleIteratorGetItemSource, is_constant_source as is_constant_source
from ..utils import HAS_NUMPY as HAS_NUMPY, clone_input as clone_input, get_fake_value as get_fake_value, getfile as getfile, global_key_name as global_key_name, is_namedtuple as is_namedtuple, is_numpy_int_type as is_numpy_int_type, is_typing as is_typing, istensor as istensor, istype as istype, np as np, odict_values as odict_values, preserve_rng_state as preserve_rng_state, tuple_iterator as tuple_iterator, tuple_iterator_getitem as tuple_iterator_getitem, tuple_iterator_len as tuple_iterator_len, wrap_fake_exception as wrap_fake_exception
from .base import MutableLocal as MutableLocal, typestr as typestr
from .builtin import BuiltinVariable as BuiltinVariable
from .constant import ConstantVariable as ConstantVariable, EnumVariable as EnumVariable
from .dicts import ConstDictVariable as ConstDictVariable, DataClassVariable as DataClassVariable, DefaultDictVariable as DefaultDictVariable, HFPretrainedConfigVariable as HFPretrainedConfigVariable
from .functions import UserFunctionVariable as UserFunctionVariable
from .lists import ListVariable as ListVariable, NamedTupleVariable as NamedTupleVariable, RangeVariable as RangeVariable, SizeVariable as SizeVariable, SliceVariable as SliceVariable, TupleIteratorVariable as TupleIteratorVariable, TupleVariable as TupleVariable
from .misc import AutogradFunctionContextVariable as AutogradFunctionContextVariable, AutogradFunctionVariable as AutogradFunctionVariable, ComptimeVariable as ComptimeVariable, GetAttrVariable as GetAttrVariable, InspectSignatureVariable as InspectSignatureVariable, LambdaVariable as LambdaVariable, NumpyVariable as NumpyVariable, PythonModuleVariable as PythonModuleVariable, SkipFilesVariable as SkipFilesVariable, TypingVariable as TypingVariable
from .nn_module import UnspecializedNNModuleVariable as UnspecializedNNModuleVariable
from .tensor import SymNodeVariable as SymNodeVariable, TensorVariable as TensorVariable, TensorWithTFOverrideVariable as TensorWithTFOverrideVariable, UnspecializedPythonVariable as UnspecializedPythonVariable
from .torch import TorchPyOperator as TorchPyOperator, TorchVariable as TorchVariable, tensor_dunder_fns as tensor_dunder_fns, torch_special_class_types as torch_special_class_types
from .user_defined import UserDefinedClassVariable as UserDefinedClassVariable, UserDefinedObjectVariable as UserDefinedObjectVariable
from _typeshed import Incomplete
from torch import SymInt as SymInt
from torch._guards import GuardSource as GuardSource
from torch._ops import PyOperator as PyOperator
from torch._subclasses.fake_tensor import FakeTensor as FakeTensor
from torch.fx.immutable_collections import immutable_list as immutable_list
from typing import Any

class _missing: ...

@dataclasses.dataclass
class GraphArg:
    source: Source
    example: Any
    is_unspecialized: bool
    fake_tensor: torch._subclasses.fake_tensor.FakeTensor | None
    is_tensor: bool = ...
    def __post_init__(self) -> None: ...
    def load(self, tx): ...
    def get_examples(self): ...
    def get_fake_examples(self): ...
    def __len__(self) -> int: ...
    def erase(self) -> None: ...
    def __init__(self, source, example, is_unspecialized, fake_tensor, is_tensor) -> None: ...

class VariableBuilder:
    """Wrap a python value in a VariableTracker() instance"""
    tx: Incomplete
    source: Incomplete
    name: Incomplete
    def __init__(self, tx, source: Source) -> None: ...
    def __call__(self, value): ...
    @staticmethod
    def list_type(value): ...
    def get_source(self): ...
    def options(self): ...
    def make_guards(self, *guards): ...
    def tensor_can_be_dict_key(self, value): ...
    def tensor_should_specialize(self): ...
    def wrap_sym(self, value: torch.SymInt | torch.SymFloat): ...
    def wrap_tensor(self, value: torch.Tensor): ...
    def wrap_unspecialized_primitive(self, value): ...

def wrap_fx_proxy(tx, proxy, example_value: Incomplete | None = None, **options): ...
def wrap_fx_proxy_cls(target_cls, tx, proxy, example_value: Incomplete | None = None, ignore_subclass: bool = False, **options): ...

@dataclasses.dataclass
class TrackedFake:
    fake: FakeTensor | SymInt
    source: Source
    def __init__(self, fake, source) -> None: ...

def wrap_to_fake_tensor_and_record(e, tx, ignore_subclass: bool = False, *, source: Source | None, is_tensor: bool): ...
