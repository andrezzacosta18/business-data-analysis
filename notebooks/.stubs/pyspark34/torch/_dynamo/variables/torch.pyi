from .. import config as config, variables as variables
from ..allowed_functions import torch_get_name as torch_get_name
from ..exc import unimplemented as unimplemented
from ..source import GetItemSource as GetItemSource, NNModuleSource as NNModuleSource
from ..utils import HAS_NUMPY as HAS_NUMPY, check_constant_args as check_constant_args, check_unspec_python_args as check_unspec_python_args, istype as istype, np as np, product as product, proxy_args_kwargs as proxy_args_kwargs, specialize_args_kwargs as specialize_args_kwargs, tensortype_to_dtype as tensortype_to_dtype
from .base import VariableTracker as VariableTracker
from .lists import ListVariable as ListVariable, TupleVariable as TupleVariable
from .misc import AutocastModeVariable as AutocastModeVariable, NullContextVariable as NullContextVariable
from .tensor import TensorWithTFOverrideVariable as TensorWithTFOverrideVariable
from _typeshed import Incomplete
from torch._dynamo.utils import get_fake_value as get_fake_value
from torch._dynamo.variables import SymNodeVariable as SymNodeVariable
from torch._guards import GuardsCheckpointState as GuardsCheckpointState
from typing import Dict, List

log: Incomplete
tensor_dunder_fns: Incomplete
torch_special_class_types: Incomplete
REWRITE_OPS_TO_TENSOR_SIZE_METHOD: Incomplete
constant_fold_functions: Incomplete

def remap_as_fn___radd__(*args): ...
def remap_as_fn___rmul__(*args): ...
def remap_as_fn___ror__(*args): ...
def remap_as_fn___rxor__(*args): ...
def remap_as_fn___rand__(*args): ...

tensor_dunder_fns_remap: Incomplete

class TorchVariable(VariableTracker):
    """Points to a module or method in torch.*"""
    value: Incomplete
    def __init__(self, value, **kwargs) -> None: ...
    def unique_var_name(self): ...
    def reconstruct(self, codegen): ...
    def as_proxy(self): ...
    def python_type(self): ...
    def as_python_constant(self): ...
    def can_constant_fold_through(self): ...
    def call_function(self, tx, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]) -> VariableTracker: ...
    def is_dynamic_shapes(self, args, kwargs):
        """Check for dynamic shapes when shape specialization is enabled"""

class TorchPyOperator(VariableTracker):
    value: Incomplete
    def __init__(self, value, **kwargs) -> None: ...
    def call_function(self, tx, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]) -> VariableTracker: ...
