from ..util import fullname as fullname, http_get as http_get, import_from_string as import_from_string
from .tokenizer import WhitespaceTokenizer as WhitespaceTokenizer, WordTokenizer as WordTokenizer
from _typeshed import Incomplete
from torch import Tensor as Tensor, nn
from typing import List

logger: Incomplete

class WordEmbeddings(nn.Module):
    embeddings_dimension: Incomplete
    emb_layer: Incomplete
    tokenizer: Incomplete
    update_embeddings: Incomplete
    max_seq_length: Incomplete
    def __init__(self, tokenizer: WordTokenizer, embedding_weights, update_embeddings: bool = False, max_seq_length: int = 1000000) -> None: ...
    def forward(self, features): ...
    def tokenize(self, texts: List[str]): ...
    def get_word_embedding_dimension(self) -> int: ...
    def save(self, output_path: str): ...
    def get_config_dict(self): ...
    @staticmethod
    def load(input_path: str): ...
    @staticmethod
    def from_text_file(embeddings_file_path: str, update_embeddings: bool = False, item_separator: str = ' ', tokenizer=..., max_vocab_size: int = None): ...
